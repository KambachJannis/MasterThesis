{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "focused-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.backends import cudnn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "cudnn.benchmark = True\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# System\n",
    "import os\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "# Custom\n",
    "import models\n",
    "import datasets\n",
    "from helpers import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-generation",
   "metadata": {},
   "source": [
    "# LCFCN Model\n",
    "\n",
    "Locates Objects with Point Supervision Training\n",
    "\n",
    "Based on https://github.com/ElementAI/LCFCN\n",
    "\n",
    "Experiment Settings below could eventually be removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "clear-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 1,\n",
      " 'dataset': {'name': 'trancos', 'transform': 'rgb_normalize'},\n",
      " 'dataset_size': {'train': 5, 'val': 5},\n",
      " 'lr': 1e-05,\n",
      " 'max_epoch': 5,\n",
      " 'model': {'base': 'fcn8_vgg16', 'name': 'lcfcn'},\n",
      " 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "####################### EXPERIMENT SETTINGS ################################\n",
    "EXP_GROUPS = {}\n",
    "EXP_GROUPS['trancos'] = {\"dataset\": {'name': 'trancos', \n",
    "                                     'transform': 'rgb_normalize'},\n",
    "                         \"model\": {'name': 'lcfcn',\n",
    "                                   'base': \"fcn8_vgg16\"},\n",
    "                         \"batch_size\": [1, 5, 10],\n",
    "                         \"max_epoch\": [100],\n",
    "                         'dataset_size': [{'train': 'all', \n",
    "                                           'val': 'all'},],\n",
    "                         'optimizer': ['adam'],\n",
    "                         'lr':[1e-5]}\n",
    "\n",
    "EXP_GROUPS['trancos_debug'] = {\"dataset\": {'name': 'trancos', \n",
    "                                           'transform': 'rgb_normalize'},\n",
    "                               \"model\": {'name': 'lcfcn',\n",
    "                                         'base': \"fcn8_vgg16\"},\n",
    "                               \"batch_size\": [1, 5, 10],\n",
    "                               \"max_epoch\": [5],\n",
    "                               'dataset_size': [{'train': 5, \n",
    "                                                 'val': 5},],\n",
    "                               'optimizer':['adam'],\n",
    "                               'lr':[1e-5]}\n",
    "\n",
    "EXP_GROUPS['denmark_debug'] = {\"dataset\": {'name': 'denmark', \n",
    "                                           'transform': 'rgb_normalize'},\n",
    "                               \"model\": {'name': 'lcfcn',\n",
    "                                         'base': \"fcn8_vgg16\"},\n",
    "                               \"batch_size\": [1, 5, 10],\n",
    "                               \"max_epoch\": [5],\n",
    "                               'dataset_size': [{'train': 1, \n",
    "                                                 'val': 1},],\n",
    "                               'optimizer':['adam'],\n",
    "                               'lr':[1e-5]}\n",
    "\n",
    "EXP_GROUPS = {k: utils.cartesian(v) for k, v in EXP_GROUPS.items()}\n",
    "\n",
    "exp_group_list = [\"trancos_debug\"]\n",
    "exp_list = []\n",
    "for exp_group_name in exp_group_list:\n",
    "    exp_list += EXP_GROUPS[exp_group_name]\n",
    "exp_dict = exp_list[0]\n",
    "    \n",
    "########################## FILE SYSTEM SETTINGS ###########################\n",
    "\n",
    "savedir_base = \"/home/jovyan/work/jannis/saves/LCFCN\"\n",
    "datadir = \"/home/jovyan/work/jannis/data/TRANCOS\"\n",
    "\n",
    "############################### PRINTS ####################################\n",
    "\n",
    "pprint.pprint(exp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-savage",
   "metadata": {},
   "source": [
    "## Saving Location\n",
    "\n",
    "Create new folder for the selected experiment and save the experiment dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "harmful-killer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment saved in /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n"
     ]
    }
   ],
   "source": [
    "exp_id = utils.hashDict(exp_dict) #generate ID by hashing experiment dict\n",
    "savedir = os.path.join(savedir_base, exp_id)\n",
    "\n",
    "# Backup and Overwrite previous experiment with same name\n",
    "utils.deleteExperiment(savedir, backup_flag = True)\n",
    "print(\"Cleared previous experiment...\")\n",
    "\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "utils.saveJSON(os.path.join(savedir, \"exp_dict.json\"), exp_dict)\n",
    "print(\"Experiment saved in %s\" % savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-boards",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Introduce datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complete-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.getDataset(dataset_dict = exp_dict[\"dataset\"],\n",
    "                                 split = \"train\",\n",
    "                                 datadir = datadir,\n",
    "                                 exp_dict = exp_dict,\n",
    "                                 dataset_size = exp_dict['dataset_size'])\n",
    "val_set = datasets.getDataset(dataset_dict = exp_dict[\"dataset\"],\n",
    "                               split = \"val\",\n",
    "                               datadir = datadir,\n",
    "                               exp_dict = exp_dict,\n",
    "                               dataset_size = exp_dict['dataset_size'])\n",
    "\n",
    "train_sampler = torch.utils.data.RandomSampler(train_set, replacement=True, num_samples=2*len(val_set))\n",
    "train_loader = DataLoader(train_set,\n",
    "                          sampler = train_sampler,\n",
    "                          batch_size = exp_dict[\"batch_size\"], \n",
    "                          drop_last = True, \n",
    "                          num_workers = 2)\n",
    "\n",
    "val_sampler = torch.utils.data.SequentialSampler(val_set)\n",
    "val_loader = DataLoader(val_set,\n",
    "                        sampler = val_sampler,\n",
    "                        batch_size = 1,\n",
    "                        num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-spelling",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Load Model and underlying base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applicable-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.getModel(model_dict = exp_dict['model'],\n",
    "                         exp_dict = exp_dict,\n",
    "                         train_set = train_set).cuda()\n",
    "\n",
    "# model.opt = optimizers.get_optim(exp_dict['opt'], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-pasta",
   "metadata": {},
   "source": [
    "## Experiment Run Management \n",
    "\n",
    "Resume experiment if a previous score_list exists or start a new one from epoch 0 if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parliamentary-devil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning new experiment from epoch 0\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(savedir, \"model.pth\")\n",
    "score_list_path = os.path.join(savedir, \"score_list.pkl\")\n",
    "\n",
    "if os.path.exists(score_list_path): #resume\n",
    "    model.loadStateDict(utils.loadTorch(model_path))\n",
    "    score_list = utils.loadPKL(score_list_path)\n",
    "    s_epoch = score_list[-1]['epoch'] + 1\n",
    "    print(f\"Resuming previous experiment fom epoch {s_epoch}\")\n",
    "else: #restart\n",
    "    score_list = []\n",
    "    s_epoch = 0\n",
    "    print(f\"Beginning new experiment from epoch {s_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-commission",
   "metadata": {},
   "source": [
    "## Main Epoch Loop\n",
    "\n",
    "Each epoch conists of training, validation, updating the statstics and saving the best as well as the most recent model and validation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seeing-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training. Loss: 50.1538: 100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating. MAE: 41.0000:  20%|██        | 1/5 [00:01<00:04,  1.18s/it]\n",
      "Validating. MAE: 43.5000:  40%|████      | 2/5 [00:02<00:03,  1.04s/it]\n",
      "Validating. MAE: 41.0000:  60%|██████    | 3/5 [00:02<00:01,  1.29it/s]\n",
      "Validating. MAE: 44.0000:  80%|████████  | 4/5 [00:03<00:00,  1.43it/s]\n",
      "Validating. MAE: 44.6000: 100%|██████████| 5/5 [00:04<00:00,  1.26it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.19it/s]\u001b[A\n",
      "Validating. MAE: 44.6000: 100%|██████████| 5/5 [00:04<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done..\n",
      "\n",
      "    val_mae  val_score  train_loss  epoch\n",
      "0     44.6      -44.6   50.153827      0 \n",
      "\n",
      "Checkpoint Saved: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n",
      "Epoch 1 of 5 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training. Loss: 45.1515: 100%|██████████| 10/10 [00:01<00:00,  5.10it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating. MAE: 25.0000:  20%|██        | 1/5 [00:00<00:01,  3.38it/s]\n",
      "Validating. MAE: 28.0000:  40%|████      | 2/5 [00:00<00:00,  4.33it/s]\n",
      "Validating. MAE: 28.0000:  60%|██████    | 3/5 [00:00<00:00,  4.86it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.47it/s]5 [00:00<00:00,  5.57it/s]\n",
      "Validating. MAE: 32.8000: 100%|██████████| 5/5 [00:00<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done..\n",
      "\n",
      "    val_mae  val_score  train_loss  epoch\n",
      "0     44.6      -44.6   50.153827      0\n",
      "1     32.8      -32.8   45.151526      1 \n",
      "\n",
      "Checkpoint Saved: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n",
      "Epoch 2 of 5 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training. Loss: 44.6693: 100%|██████████| 10/10 [00:02<00:00,  4.11it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating. MAE: 29.0000:  20%|██        | 1/5 [00:00<00:01,  3.42it/s]\n",
      "Validating. MAE: 29.5000:  40%|████      | 2/5 [00:00<00:00,  4.00it/s]\n",
      "Validating. MAE: 27.3333:  60%|██████    | 3/5 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.84it/s]5 [00:00<00:00,  4.72it/s]\n",
      "Validating. MAE: 28.8000: 100%|██████████| 5/5 [00:01<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done..\n",
      "\n",
      "    val_mae  val_score  train_loss  epoch\n",
      "0     44.6      -44.6   50.153827      0\n",
      "1     32.8      -32.8   45.151526      1\n",
      "2     28.8      -28.8   44.669345      2 \n",
      "\n",
      "Checkpoint Saved: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n",
      "Epoch 3 of 5 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training. Loss: 42.0703: 100%|██████████| 10/10 [00:02<00:00,  3.78it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating. MAE: 30.0000:  20%|██        | 1/5 [00:00<00:01,  3.55it/s]\n",
      "Validating. MAE: 27.5000:  40%|████      | 2/5 [00:00<00:00,  3.68it/s]\n",
      "Validating. MAE: 24.6667:  60%|██████    | 3/5 [00:00<00:00,  3.79it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.42it/s]5 [00:01<00:00,  4.10it/s]\n",
      "Validating. MAE: 25.0000: 100%|██████████| 5/5 [00:01<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done..\n",
      "\n",
      "    val_mae  val_score  train_loss  epoch\n",
      "0     44.6      -44.6   50.153827      0\n",
      "1     32.8      -32.8   45.151526      1\n",
      "2     28.8      -28.8   44.669345      2\n",
      "3     25.0      -25.0   42.070331      3 \n",
      "\n",
      "Checkpoint Saved: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n",
      "Epoch 4 of 5 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training. Loss: 38.7645: 100%|██████████| 10/10 [00:02<00:00,  3.55it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating. MAE: 22.0000:  20%|██        | 1/5 [00:00<00:01,  3.68it/s]\n",
      "Validating. MAE: 21.5000:  40%|████      | 2/5 [00:00<00:00,  3.41it/s]\n",
      "Validating. MAE: 20.0000:  60%|██████    | 3/5 [00:00<00:00,  3.36it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.04it/s]5 [00:01<00:00,  3.71it/s]\n",
      "Validating. MAE: 22.8000: 100%|██████████| 5/5 [00:01<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done..\n",
      "\n",
      "    val_mae  val_score  train_loss  epoch\n",
      "0     44.6      -44.6   50.153827      0\n",
      "1     32.8      -32.8   45.151526      1\n",
      "2     28.8      -28.8   44.669345      2\n",
      "3     25.0      -25.0   42.070331      3\n",
      "4     22.8      -22.8   38.764454      4 \n",
      "\n",
      "Checkpoint Saved: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n",
      "Saved Best: /home/jovyan/work/jannis/saves/LCFCN/b64501300fd5500efb7d3ef455b67732\n",
      "Epoch 5 of 5 completed.\n",
      "Experiment completed!\n"
     ]
    }
   ],
   "source": [
    "for e in range(s_epoch, exp_dict['max_epoch']):\n",
    "    # Validate only at the start of each cycle\n",
    "    score_dict = {}\n",
    "    # Train the model\n",
    "    train_dict = model.trainOnLoader(model, train_loader)\n",
    "    print(\"Training done...\")\n",
    "    # Validate and Visualize the model\n",
    "    val_dict = model.valOnLoader(val_loader, savedir_images=os.path.join(savedir, \"images\"), n_images=3)\n",
    "    # model.visOnLoader(vis_loader, savedir=os.path.join(savedir, \"images\"))\n",
    "    print(\"Validation done..\")\n",
    "    \n",
    "    # Update score_dict and add to score_list\n",
    "    score_dict.update(val_dict)\n",
    "    score_dict.update(train_dict)\n",
    "    score_dict[\"epoch\"] = len(score_list)\n",
    "    score_list += [score_dict]\n",
    "\n",
    "    # Report score_list\n",
    "    score_df = pd.DataFrame(score_list)\n",
    "    print(\"\\n\", score_df.tail(), \"\\n\")\n",
    "    \n",
    "    # Save Model and score_list\n",
    "    utils.saveTorch(model_path, model.getStateDict())\n",
    "    utils.savePKL(score_list_path, score_list)\n",
    "    print(\"Checkpoint Saved: %s\" % savedir)\n",
    "\n",
    "    # Save best Checkpoint\n",
    "    if e == 0 or (score_dict.get(\"val_score\", 0) > score_df[\"val_score\"][:-1].fillna(0).max()):\n",
    "        utils.savePKL(os.path.join(savedir, \"score_list_best.pkl\"), score_list)\n",
    "        utils.saveTorch(os.path.join(savedir, \"model_best.pth\"), model.getStateDict())\n",
    "        print(\"Saved Best: %s\" % savedir)\n",
    "    print(f\"Epoch {e+1} of {exp_dict['max_epoch'] - s_epoch} completed.\")\n",
    "\n",
    "print(f\"Experiment completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
