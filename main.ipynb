{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "computational-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.backends import cudnn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "cudnn.benchmark = True\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# System\n",
    "import os\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "# Custom\n",
    "import models\n",
    "import datasets\n",
    "from helpers import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-billion",
   "metadata": {},
   "source": [
    "# LCFCN Model\n",
    "\n",
    "Locates Objects with Point Supervision Training\n",
    "\n",
    "Based on https://github.com/ElementAI/LCFCN\n",
    "\n",
    "Experiment Settings below could eventually be removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "virgin-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 1,\n",
      " 'dataset': {'name': 'denmark', 'transform': 'rgb_normalize'},\n",
      " 'dataset_size': {'train': 800, 'val': 400},\n",
      " 'lr': 1e-05,\n",
      " 'max_epoch': 5,\n",
      " 'model': {'base': 'fcn8_vgg16', 'name': 'lcfcn'},\n",
      " 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "####################### EXPERIMENT SETTINGS ################################\n",
    "EXP_GROUPS = {}\n",
    "EXP_GROUPS['trancos'] = {\"dataset\": {'name': 'trancos', \n",
    "                                     'transform': 'rgb_normalize'},\n",
    "                         \"model\": {'name': 'lcfcn',\n",
    "                                   'base': \"fcn8_vgg16\"},\n",
    "                         \"batch_size\": [1, 5, 10],\n",
    "                         \"max_epoch\": [100],\n",
    "                         'dataset_size': [{'train': 'all', \n",
    "                                           'val': 'all'},],\n",
    "                         'optimizer': ['adam'],\n",
    "                         'lr':[1e-5]}\n",
    "\n",
    "EXP_GROUPS['trancos_debug'] = {\"dataset\": {'name': 'trancos', \n",
    "                                           'transform': 'rgb_normalize'},\n",
    "                               \"model\": {'name': 'lcfcn',\n",
    "                                         'base': \"fcn8_vgg16\"},\n",
    "                               \"batch_size\": [1, 5, 10],\n",
    "                               \"max_epoch\": [5],\n",
    "                               'dataset_size': [{'train': 5, \n",
    "                                                 'val': 5},],\n",
    "                               'optimizer':['adam'],\n",
    "                               'lr':[1e-5]}\n",
    "\n",
    "EXP_GROUPS['denmark_debug'] = {\"dataset\": {'name': 'denmark', \n",
    "                                           'transform': 'rgb_normalize'},\n",
    "                               \"model\": {'name': 'lcfcn',\n",
    "                                         'base': \"fcn8_vgg16\"},\n",
    "                               \"batch_size\": [1, 5, 10],\n",
    "                               \"max_epoch\": [5],\n",
    "                               'dataset_size': [{'train': 800, \n",
    "                                                 'val': 400},],\n",
    "                               'optimizer':['adam'],\n",
    "                               'lr':[1e-5]}\n",
    "\n",
    "EXP_GROUPS['trancos_debug_wtp'] = {\"dataset\": {'name': 'trancos', \n",
    "                                           'transform': 'rgb_normalize'},\n",
    "                               \"model\": {'name': 'wtp',\n",
    "                                         'base': \"wtp_vgg16\"},\n",
    "                               \"batch_size\": [1, 20],\n",
    "                               \"max_epoch\": [5],\n",
    "                               'dataset_size': [{'train': 5, \n",
    "                                                 'val': 5},],\n",
    "                               'optimizer':['sdg'],\n",
    "                               'lr':[1e-5]}\n",
    "\n",
    "EXP_GROUPS = {k: utils.cartesian(v) for k, v in EXP_GROUPS.items()}\n",
    "\n",
    "exp_group_list = [\"denmark_debug\"]\n",
    "exp_list = []\n",
    "for exp_group_name in exp_group_list:\n",
    "    exp_list += EXP_GROUPS[exp_group_name]\n",
    "exp_dict = exp_list[0]\n",
    "    \n",
    "########################## FILE SYSTEM SETTINGS ###########################\n",
    "\n",
    "savedir_base = \"/home/jovyan/work/saves/LCFCN\"\n",
    "datadir = \"/home/jovyan/work/data/DENMARK\"\n",
    "\n",
    "############################### PRINTS ####################################\n",
    "\n",
    "pprint.pprint(exp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-blend",
   "metadata": {},
   "source": [
    "## Saving Location\n",
    "\n",
    "Create new folder for the selected experiment and save the experiment dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "graduate-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared previous experiment...\n",
      "Experiment saved in /home/jovyan/work/jannis/saves/LCFCN/730774860cf026c8606e5fd35fe421d1\n"
     ]
    }
   ],
   "source": [
    "exp_id = utils.hashDict(exp_dict) #generate ID by hashing experiment dict\n",
    "savedir = os.path.join(savedir_base, exp_id)\n",
    "\n",
    "# Backup and Overwrite previous experiment with same name\n",
    "utils.deleteExperiment(savedir, backup_flag = True)\n",
    "print(\"Cleared previous experiment...\")\n",
    "\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "utils.saveJSON(os.path.join(savedir, \"exp_dict.json\"), exp_dict)\n",
    "print(\"Experiment saved in %s\" % savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-tobago",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Introduce datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controversial-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.getDataset(dataset_dict = exp_dict[\"dataset\"],\n",
    "                                 split = \"train\",\n",
    "                                 datadir = datadir,\n",
    "                                 exp_dict = exp_dict,\n",
    "                                 dataset_size = exp_dict['dataset_size'])\n",
    "val_set = datasets.getDataset(dataset_dict = exp_dict[\"dataset\"],\n",
    "                               split = \"val\",\n",
    "                               datadir = datadir,\n",
    "                               exp_dict = exp_dict,\n",
    "                               dataset_size = exp_dict['dataset_size'])\n",
    "\n",
    "train_sampler = torch.utils.data.RandomSampler(train_set, replacement=True, num_samples=2*len(val_set))\n",
    "train_loader = DataLoader(train_set,\n",
    "                          sampler = train_sampler,\n",
    "                          batch_size = exp_dict[\"batch_size\"], \n",
    "                          drop_last = True, \n",
    "                          num_workers = 2)\n",
    "\n",
    "val_sampler = torch.utils.data.SequentialSampler(val_set)\n",
    "val_loader = DataLoader(val_set,\n",
    "                        sampler = val_sampler,\n",
    "                        batch_size = 1,\n",
    "                        num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-uncertainty",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Load Model and underlying base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amazing-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.getModel(model_dict = exp_dict['model'],\n",
    "                         exp_dict = exp_dict,\n",
    "                         train_set = train_set).cuda()\n",
    "\n",
    "# model.opt = optimizers.get_optim(exp_dict['opt'], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-despite",
   "metadata": {},
   "source": [
    "## Experiment Run Management \n",
    "\n",
    "Resume experiment if a previous score_list exists or start a new one from epoch 0 if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acknowledged-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning new experiment from epoch 0\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(savedir, \"model.pth\")\n",
    "score_list_path = os.path.join(savedir, \"score_list.pkl\")\n",
    "\n",
    "if os.path.exists(score_list_path): #resume\n",
    "    model.loadStateDict(utils.loadTorch(model_path))\n",
    "    score_list = utils.loadPKL(score_list_path)\n",
    "    s_epoch = score_list[-1]['epoch'] + 1\n",
    "    print(f\"Resuming previous experiment fom epoch {s_epoch}\")\n",
    "else: #restart\n",
    "    score_list = []\n",
    "    s_epoch = 0\n",
    "    print(f\"Beginning new experiment from epoch {s_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-marine",
   "metadata": {},
   "source": [
    "## Main Epoch Loop\n",
    "\n",
    "Each epoch conists of training, validation, updating the statstics and saving the best as well as the most recent model and validation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-notice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training. Loss: 1.6711: 100%|██████████| 800/800 [02:01<00:00,  6.59it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating. MAE: 3.0000:   0%|          | 1/400 [00:00<04:12,  1.58it/s]\n",
      "Validating. MAE: 2.0000:   1%|          | 3/400 [00:00<01:47,  3.71it/s]\n",
      "Validating. MAE: 2.6000:   1%|▏         | 5/400 [00:01<01:21,  4.85it/s]\n",
      "Validating. MAE: 2.0000:   2%|▏         | 7/400 [00:01<01:10,  5.54it/s]\n",
      "Validating. MAE: 2.1111:   2%|▏         | 9/400 [00:01<01:05,  5.98it/s]\n",
      "Validating. MAE: 1.8182:   3%|▎         | 11/400 [00:02<01:01,  6.29it/s]\n",
      "Validating. MAE: 1.6154:   3%|▎         | 13/400 [00:02<00:59,  6.48it/s]\n",
      "Validating. MAE: 1.5333:   4%|▍         | 15/400 [00:02<00:58,  6.61it/s]\n",
      "Validating. MAE: 1.4706:   4%|▍         | 17/400 [00:02<00:57,  6.71it/s]\n",
      "Validating. MAE: 1.4737:   5%|▍         | 19/400 [00:03<00:56,  6.77it/s]\n",
      "Validating. MAE: 1.3810:   5%|▌         | 21/400 [00:03<00:58,  6.50it/s]\n",
      "Validating. MAE: 1.3043:   6%|▌         | 23/400 [00:03<00:57,  6.60it/s]\n",
      "Validating. MAE: 1.2800:   6%|▋         | 25/400 [00:04<00:56,  6.69it/s]\n",
      "Validating. MAE: 1.2963:   7%|▋         | 27/400 [00:04<00:55,  6.76it/s]\n",
      "Validating. MAE: 1.2759:   7%|▋         | 29/400 [00:04<00:54,  6.80it/s]\n",
      "Validating. MAE: 1.2258:   8%|▊         | 31/400 [00:05<00:54,  6.83it/s]\n",
      "Validating. MAE: 1.1515:   8%|▊         | 33/400 [00:05<00:54,  6.79it/s]\n",
      "Validating. MAE: 1.2000:   9%|▉         | 35/400 [00:05<00:53,  6.80it/s]\n",
      "Validating. MAE: 1.2162:   9%|▉         | 37/400 [00:05<00:53,  6.84it/s]\n",
      "Validating. MAE: 1.3077:  10%|▉         | 39/400 [00:06<00:52,  6.86it/s]\n",
      "Validating. MAE: 1.3902:  10%|█         | 41/400 [00:06<00:52,  6.87it/s]\n",
      "Validating. MAE: 1.3953:  11%|█         | 43/400 [00:06<00:52,  6.84it/s]\n",
      "Validating. MAE: 1.3778:  11%|█▏        | 45/400 [00:07<00:55,  6.36it/s]\n",
      "Validating. MAE: 1.3617:  12%|█▏        | 47/400 [00:07<00:54,  6.49it/s]\n",
      "Validating. MAE: 1.3878:  12%|█▏        | 49/400 [00:07<00:53,  6.57it/s]\n",
      "Validating. MAE: 1.4510:  13%|█▎        | 51/400 [00:08<00:52,  6.62it/s]\n",
      "Validating. MAE: 1.3962:  13%|█▎        | 53/400 [00:08<00:51,  6.68it/s]\n",
      "Validating. MAE: 1.4182:  14%|█▍        | 55/400 [00:08<00:51,  6.70it/s]\n",
      "Validating. MAE: 1.4035:  14%|█▍        | 57/400 [00:08<00:51,  6.72it/s]\n",
      "Validating. MAE: 1.4407:  15%|█▍        | 59/400 [00:09<00:50,  6.73it/s]\n",
      "Validating. MAE: 1.4754:  15%|█▌        | 61/400 [00:09<00:50,  6.75it/s]\n",
      "Validating. MAE: 1.4603:  16%|█▌        | 63/400 [00:09<00:49,  6.76it/s]\n",
      "Validating. MAE: 1.4615:  16%|█▋        | 65/400 [00:10<00:49,  6.76it/s]\n",
      "Validating. MAE: 1.4478:  17%|█▋        | 67/400 [00:10<00:49,  6.77it/s]\n",
      "Validating. MAE: 1.4058:  17%|█▋        | 69/400 [00:10<00:49,  6.73it/s]\n",
      "Validating. MAE: 1.3944:  18%|█▊        | 71/400 [00:10<00:48,  6.74it/s]\n",
      "Validating. MAE: 1.3699:  18%|█▊        | 73/400 [00:11<00:48,  6.76it/s]\n",
      "Validating. MAE: 1.3600:  19%|█▉        | 75/400 [00:11<00:48,  6.76it/s]\n",
      "Validating. MAE: 1.3766:  19%|█▉        | 77/400 [00:11<00:47,  6.77it/s]\n",
      "Validating. MAE: 1.3418:  20%|█▉        | 79/400 [00:12<00:47,  6.76it/s]\n",
      "Validating. MAE: 1.3086:  20%|██        | 81/400 [00:12<00:46,  6.80it/s]\n",
      "Validating. MAE: 1.3133:  21%|██        | 83/400 [00:12<00:46,  6.78it/s]\n",
      "Validating. MAE: 1.2824:  21%|██▏       | 85/400 [00:13<00:46,  6.71it/s]\n",
      "Validating. MAE: 1.2644:  22%|██▏       | 87/400 [00:13<00:46,  6.72it/s]\n",
      "Validating. MAE: 1.2921:  22%|██▏       | 89/400 [00:13<00:46,  6.72it/s]\n",
      "Validating. MAE: 1.2967:  23%|██▎       | 91/400 [00:13<00:45,  6.72it/s]\n",
      "Validating. MAE: 1.2796:  23%|██▎       | 93/400 [00:14<00:45,  6.71it/s]\n",
      "Validating. MAE: 1.2947:  24%|██▍       | 95/400 [00:14<00:45,  6.72it/s]\n",
      "Validating. MAE: 1.3299:  24%|██▍       | 97/400 [00:14<00:46,  6.45it/s]\n",
      "Validating. MAE: 1.3434:  25%|██▍       | 99/400 [00:15<00:46,  6.53it/s]\n",
      "Validating. MAE: 1.3168:  25%|██▌       | 101/400 [00:15<00:45,  6.60it/s]\n",
      "Validating. MAE: 1.3010:  26%|██▌       | 103/400 [00:15<00:45,  6.52it/s]\n",
      "Validating. MAE: 1.3048:  26%|██▋       | 105/400 [00:16<00:44,  6.58it/s]\n",
      "Validating. MAE: 1.2897:  27%|██▋       | 107/400 [00:16<00:44,  6.60it/s]\n",
      "Validating. MAE: 1.2844:  27%|██▋       | 109/400 [00:16<00:43,  6.63it/s]\n",
      "Validating. MAE: 1.2703:  28%|██▊       | 111/400 [00:16<00:43,  6.65it/s]\n",
      "Validating. MAE: 1.2743:  28%|██▊       | 113/400 [00:17<00:43,  6.67it/s]\n",
      "Validating. MAE: 1.2870:  29%|██▉       | 115/400 [00:17<00:42,  6.67it/s]\n",
      "Validating. MAE: 1.2735:  29%|██▉       | 117/400 [00:17<00:42,  6.67it/s]\n",
      "Validating. MAE: 1.2521:  30%|██▉       | 119/400 [00:18<00:42,  6.67it/s]\n",
      "Validating. MAE: 1.2397:  30%|███       | 121/400 [00:18<00:41,  6.71it/s]\n",
      "Validating. MAE: 1.2764:  31%|███       | 123/400 [00:18<00:41,  6.71it/s]\n",
      "Validating. MAE: 1.2720:  31%|███▏      | 125/400 [00:19<00:41,  6.70it/s]\n",
      "Validating. MAE: 1.2677:  32%|███▏      | 127/400 [00:19<00:40,  6.70it/s]\n",
      "Validating. MAE: 1.2713:  32%|███▏      | 129/400 [00:19<00:40,  6.68it/s]\n",
      "Validating. MAE: 1.2748:  33%|███▎      | 131/400 [00:19<00:40,  6.68it/s]\n",
      "Validating. MAE: 1.2556:  33%|███▎      | 133/400 [00:20<00:39,  6.68it/s]\n",
      "Validating. MAE: 1.2519:  34%|███▍      | 135/400 [00:20<00:39,  6.68it/s]\n",
      "Validating. MAE: 1.2701:  34%|███▍      | 137/400 [00:20<00:39,  6.67it/s]\n",
      "Validating. MAE: 1.2590:  35%|███▍      | 139/400 [00:21<00:39,  6.66it/s]\n",
      "Validating. MAE: 1.2553:  35%|███▌      | 141/400 [00:21<00:38,  6.66it/s]\n",
      "Validating. MAE: 1.2378:  36%|███▌      | 143/400 [00:21<00:38,  6.67it/s]\n",
      "Validating. MAE: 1.2276:  36%|███▋      | 145/400 [00:22<00:38,  6.67it/s]\n",
      "Validating. MAE: 1.2245:  37%|███▋      | 147/400 [00:22<00:37,  6.69it/s]\n",
      "Validating. MAE: 1.2215:  37%|███▋      | 149/400 [00:22<00:37,  6.69it/s]\n",
      "Validating. MAE: 1.2053:  38%|███▊      | 151/400 [00:22<00:37,  6.69it/s]\n",
      "Validating. MAE: 1.2092:  38%|███▊      | 153/400 [00:23<00:36,  6.70it/s]\n",
      "Validating. MAE: 1.2129:  39%|███▉      | 155/400 [00:23<00:36,  6.69it/s]\n",
      "Validating. MAE: 1.1975:  39%|███▉      | 157/400 [00:23<00:36,  6.70it/s]\n",
      "Validating. MAE: 1.1950:  40%|███▉      | 159/400 [00:24<00:36,  6.68it/s]\n",
      "Validating. MAE: 1.1801:  40%|████      | 161/400 [00:24<00:35,  6.69it/s]\n",
      "Validating. MAE: 1.2147:  41%|████      | 163/400 [00:24<00:35,  6.69it/s]\n",
      "Validating. MAE: 1.2182:  41%|████▏     | 165/400 [00:25<00:35,  6.69it/s]\n",
      "Validating. MAE: 1.2036:  42%|████▏     | 167/400 [00:25<00:34,  6.69it/s]\n",
      "Validating. MAE: 1.2071:  42%|████▏     | 169/400 [00:25<00:34,  6.69it/s]\n",
      "Validating. MAE: 1.2105:  43%|████▎     | 171/400 [00:25<00:34,  6.68it/s]\n",
      "Validating. MAE: 1.2139:  43%|████▎     | 173/400 [00:26<00:34,  6.65it/s]\n",
      "Validating. MAE: 1.2114:  44%|████▍     | 175/400 [00:26<00:33,  6.68it/s]\n",
      "Validating. MAE: 1.1977:  44%|████▍     | 177/400 [00:26<00:33,  6.68it/s]\n",
      "Validating. MAE: 1.2011:  45%|████▍     | 179/400 [00:27<00:33,  6.68it/s]\n",
      "Validating. MAE: 1.1934:  45%|████▌     | 181/400 [00:27<00:32,  6.68it/s]\n",
      "Validating. MAE: 1.2077:  46%|████▌     | 183/400 [00:27<00:32,  6.70it/s]\n",
      "Validating. MAE: 1.2054:  46%|████▋     | 185/400 [00:28<00:32,  6.67it/s]\n",
      "Validating. MAE: 1.1925:  47%|████▋     | 187/400 [00:28<00:31,  6.69it/s]\n",
      "Validating. MAE: 1.1905:  47%|████▋     | 189/400 [00:28<00:31,  6.68it/s]\n",
      "Validating. MAE: 1.1990:  48%|████▊     | 191/400 [00:28<00:31,  6.70it/s]\n",
      "Validating. MAE: 1.1969:  48%|████▊     | 193/400 [00:29<00:30,  6.70it/s]\n",
      "Validating. MAE: 1.2051:  49%|████▉     | 195/400 [00:29<00:30,  6.70it/s]\n",
      "Validating. MAE: 1.1980:  49%|████▉     | 197/400 [00:29<00:30,  6.70it/s]\n",
      "Validating. MAE: 1.2010:  50%|████▉     | 199/400 [00:30<00:30,  6.69it/s]\n",
      "Validating. MAE: 1.1990:  50%|█████     | 201/400 [00:30<00:29,  6.72it/s]\n",
      "Validating. MAE: 1.2020:  51%|█████     | 203/400 [00:30<00:29,  6.71it/s]\n",
      "Validating. MAE: 1.2049:  51%|█████▏    | 205/400 [00:31<00:29,  6.69it/s]\n",
      "Validating. MAE: 1.2126:  52%|█████▏    | 207/400 [00:31<00:28,  6.67it/s]\n",
      "Validating. MAE: 1.2153:  52%|█████▏    | 209/400 [00:31<00:28,  6.66it/s]\n",
      "Validating. MAE: 1.2559:  53%|█████▎    | 211/400 [00:31<00:28,  6.65it/s]\n",
      "Validating. MAE: 1.2864:  53%|█████▎    | 213/400 [00:32<00:28,  6.67it/s]\n",
      "Validating. MAE: 1.2791:  54%|█████▍    | 215/400 [00:32<00:27,  6.67it/s]\n",
      "Validating. MAE: 1.2673:  54%|█████▍    | 217/400 [00:32<00:27,  6.68it/s]\n",
      "Validating. MAE: 1.2648:  55%|█████▍    | 219/400 [00:33<00:27,  6.69it/s]\n",
      "Validating. MAE: 1.2579:  55%|█████▌    | 221/400 [00:33<00:26,  6.69it/s]\n",
      "Validating. MAE: 1.2466:  56%|█████▌    | 223/400 [00:33<00:26,  6.69it/s]\n",
      "Validating. MAE: 1.2444:  56%|█████▋    | 225/400 [00:34<00:26,  6.63it/s]\n",
      "Validating. MAE: 1.2335:  57%|█████▋    | 227/400 [00:34<00:25,  6.65it/s]\n",
      "Validating. MAE: 1.2402:  57%|█████▋    | 229/400 [00:34<00:25,  6.67it/s]\n",
      "Validating. MAE: 1.2424:  58%|█████▊    | 231/400 [00:34<00:25,  6.66it/s]\n",
      "Validating. MAE: 1.2403:  58%|█████▊    | 233/400 [00:35<00:25,  6.68it/s]\n",
      "Validating. MAE: 1.2468:  59%|█████▉    | 235/400 [00:35<00:24,  6.69it/s]\n",
      "Validating. MAE: 1.2405:  59%|█████▉    | 237/400 [00:35<00:24,  6.68it/s]\n",
      "Validating. MAE: 1.2343:  60%|█████▉    | 239/400 [00:36<00:24,  6.68it/s]\n",
      "Validating. MAE: 1.2407:  60%|██████    | 241/400 [00:36<00:23,  6.72it/s]\n",
      "Validating. MAE: 1.2387:  61%|██████    | 243/400 [00:36<00:23,  6.66it/s]\n",
      "Validating. MAE: 1.2449:  61%|██████▏   | 245/400 [00:37<00:23,  6.67it/s]\n",
      "Validating. MAE: 1.2551:  62%|██████▏   | 247/400 [00:37<00:22,  6.66it/s]\n",
      "Validating. MAE: 1.2530:  62%|██████▏   | 249/400 [00:37<00:22,  6.60it/s]\n",
      "Validating. MAE: 1.2590:  63%|██████▎   | 251/400 [00:37<00:22,  6.62it/s]\n",
      "Validating. MAE: 1.2806:  63%|██████▎   | 253/400 [00:38<00:22,  6.49it/s]\n",
      "Validating. MAE: 1.2863:  64%|██████▍   | 255/400 [00:38<00:22,  6.39it/s]\n",
      "Validating. MAE: 1.2918:  64%|██████▍   | 257/400 [00:38<00:22,  6.49it/s]\n",
      "Validating. MAE: 1.2857:  65%|██████▍   | 259/400 [00:39<00:21,  6.55it/s]\n",
      "Validating. MAE: 1.2874:  65%|██████▌   | 261/400 [00:39<00:21,  6.60it/s]\n",
      "Validating. MAE: 1.2814:  66%|██████▌   | 263/400 [00:39<00:20,  6.64it/s]\n",
      "Validating. MAE: 1.2755:  66%|██████▋   | 265/400 [00:40<00:20,  6.68it/s]\n",
      "Validating. MAE: 1.2734:  67%|██████▋   | 267/400 [00:40<00:19,  6.71it/s]\n",
      "Validating. MAE: 1.2937:  67%|██████▋   | 269/400 [00:40<00:19,  6.73it/s]\n",
      "Validating. MAE: 1.2952:  68%|██████▊   | 271/400 [00:40<00:19,  6.75it/s]\n",
      "Validating. MAE: 1.3004:  68%|██████▊   | 273/400 [00:41<00:18,  6.75it/s]\n",
      "Validating. MAE: 1.3055:  69%|██████▉   | 275/400 [00:41<00:18,  6.76it/s]\n",
      "Validating. MAE: 1.2996:  69%|██████▉   | 277/400 [00:41<00:18,  6.69it/s]\n",
      "Validating. MAE: 1.3118:  70%|██████▉   | 279/400 [00:42<00:18,  6.72it/s]\n",
      "Validating. MAE: 1.3132:  70%|███████   | 281/400 [00:42<00:17,  6.78it/s]\n",
      "Validating. MAE: 1.3145:  71%|███████   | 283/400 [00:42<00:17,  6.76it/s]\n",
      "Validating. MAE: 1.3158:  71%|███████▏  | 285/400 [00:43<00:16,  6.77it/s]\n",
      "Validating. MAE: 1.3206:  72%|███████▏  | 287/400 [00:43<00:16,  6.77it/s]\n",
      "Validating. MAE: 1.3149:  72%|███████▏  | 289/400 [00:43<00:16,  6.79it/s]\n",
      "Validating. MAE: 1.3162:  73%|███████▎  | 291/400 [00:43<00:16,  6.79it/s]\n",
      "Validating. MAE: 1.3140:  73%|███████▎  | 293/400 [00:44<00:15,  6.78it/s]\n",
      "Validating. MAE: 1.3186:  74%|███████▍  | 295/400 [00:44<00:15,  6.77it/s]\n",
      "Validating. MAE: 1.3199:  74%|███████▍  | 297/400 [00:44<00:15,  6.79it/s]\n",
      "Validating. MAE: 1.3244:  75%|███████▍  | 299/400 [00:45<00:14,  6.79it/s]\n",
      "Validating. MAE: 1.3223:  75%|███████▌  | 301/400 [00:45<00:14,  6.78it/s]\n",
      "Validating. MAE: 1.3168:  76%|███████▌  | 303/400 [00:45<00:14,  6.79it/s]\n",
      "Validating. MAE: 1.3246:  76%|███████▋  | 305/400 [00:45<00:13,  6.79it/s]\n",
      "Validating. MAE: 1.3257:  77%|███████▋  | 307/400 [00:46<00:13,  6.77it/s]\n",
      "Validating. MAE: 1.3204:  77%|███████▋  | 309/400 [00:46<00:13,  6.78it/s]\n",
      "Validating. MAE: 1.3280:  78%|███████▊  | 311/400 [00:46<00:13,  6.79it/s]\n",
      "Validating. MAE: 1.3291:  78%|███████▊  | 313/400 [00:47<00:12,  6.71it/s]\n",
      "Validating. MAE: 1.3333:  79%|███████▉  | 315/400 [00:47<00:12,  6.73it/s]\n",
      "Validating. MAE: 1.3249:  79%|███████▉  | 317/400 [00:47<00:12,  6.74it/s]\n",
      "Validating. MAE: 1.3197:  80%|███████▉  | 319/400 [00:48<00:11,  6.76it/s]\n",
      "Validating. MAE: 1.3188:  80%|███████▉  | 319/400 [00:48<00:11,  6.76it/s]"
     ]
    }
   ],
   "source": [
    "for e in range(s_epoch, exp_dict['max_epoch']):\n",
    "    # Validate only at the start of each cycle\n",
    "    score_dict = {}\n",
    "    # Train the model\n",
    "    train_dict = model.trainOnLoader(model, train_loader)\n",
    "    print(\"Training done...\")\n",
    "    # Validate and Visualize the model\n",
    "    val_dict = model.valOnLoader(val_loader, savedir_images=os.path.join(savedir, \"images\"), n_images=3)\n",
    "    # model.visOnLoader(vis_loader, savedir=os.path.join(savedir, \"images\"))\n",
    "    print(\"Validation done..\")\n",
    "    \n",
    "    # Update score_dict and add to score_list\n",
    "    score_dict.update(val_dict)\n",
    "    score_dict.update(train_dict)\n",
    "    score_dict[\"epoch\"] = len(score_list)\n",
    "    score_list += [score_dict]\n",
    "\n",
    "    # Report score_list\n",
    "    score_df = pd.DataFrame(score_list)\n",
    "    print(\"\\n\", score_df.tail(), \"\\n\")\n",
    "    \n",
    "    # Save Model and score_list\n",
    "    utils.saveTorch(model_path, model.getStateDict())\n",
    "    utils.savePKL(score_list_path, score_list)\n",
    "    print(\"Checkpoint Saved: %s\" % savedir)\n",
    "\n",
    "    # Save best Checkpoint\n",
    "    if e == 0 or (score_dict.get(\"val_score\", 0) > score_df[\"val_score\"][:-1].fillna(0).max()):\n",
    "        utils.savePKL(os.path.join(savedir, \"score_list_best.pkl\"), score_list)\n",
    "        utils.saveTorch(os.path.join(savedir, \"model_best.pth\"), model.getStateDict())\n",
    "        print(\"Saved Best: %s\" % savedir)\n",
    "    print(f\"Epoch {e+1} of {exp_dict['max_epoch'] - s_epoch} completed.\")\n",
    "\n",
    "print(f\"Experiment completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-peace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
