{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b09563f-8a29-483d-9664-280c0d6b1de7",
   "metadata": {},
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "The purpose of this Notebook is to split all 1km x 1km regions stored as .tif-files into smaller tiles that are suitable as network inputs. Tiles will be saved as .jpg-images in a new folder along with point-labels and shape-labels as .npy-files.\n",
    "\n",
    "The final structure of the output folder will look like this:\n",
    "\n",
    "Folder name: 256x265 (width x hight of tiles) \n",
    "- images: contains individual tiles as .jpg-images with name {region name} _ {tile number}.jpg \n",
    "- points: point-labels as .npy-files, matched via filename\n",
    "- shapes: shape-labels as .npy-files, matched via filename\n",
    "- images_sets: contains a .txt-file for each split (train, val, test) with the filenames of the assigned tiles\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946fe04f-b812-4510-8c35-853d70215e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import fiona\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import rasterio as rio\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bad5f5-3e52-4db1-a5a5-c142b204cf6d",
   "metadata": {},
   "source": [
    "## Get all Images and Label-Files from Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910883d4-089f-4e40-9050-8006e906894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 Regions and 2 Label-Files\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"/home/jovyan/work\"\n",
    "DATASET = \"DENMARK\"\n",
    "IMAGETYPE = \".tif\"\n",
    "LABELTYPE = \".shp\"\n",
    "\n",
    "regions = []\n",
    "labels = []\n",
    "PATH = os.path.join(DATADIR, DATASET)\n",
    "for _, _, files in os.walk(PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(IMAGETYPE):\n",
    "            regions.append(file)\n",
    "        elif file.endswith(LABELTYPE):\n",
    "            labels.append(file)\n",
    "            \n",
    "print(f\"Found {len(regions)} Regions and {len(labels)} Label-Files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943eb38-f248-47b8-8130-9d18012b51e4",
   "metadata": {},
   "source": [
    "## Set Tile Size and Overlap\n",
    "\n",
    "To ensure equal tile sizes, overap is computed dynamically based on the amount of vertical and horizontal tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f0756c-183d-46ba-a8ab-7ef735357e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1600 tiles per region with: \n",
      " - tile size: 256 x 256 px \n",
      " - region size: 8000 x 8000 px \n",
      " - vertical overlap: 57.43589743589744 px \n",
      " - horizontal overlap: 57.43589743589744 px\n"
     ]
    }
   ],
   "source": [
    "tiles_h = 40\n",
    "tiles_v = 40\n",
    "width = 256\n",
    "height = 256\n",
    "\n",
    "example_src = rio.open(os.path.join(PATH, regions[0]))\n",
    "ncols, nrows = example_src.meta['width'], example_src.meta['height']\n",
    "h_overlap = ((tiles_h * width) - ncols) / (tiles_h - 1)\n",
    "v_overlap = ((tiles_v * height) - nrows) / (tiles_v - 1)\n",
    "\n",
    "print(f\"Generating {tiles_h * tiles_v} tiles per region with: \\n - tile size: {width} x {height} px \\n - region size: {ncols} x {nrows} px \\n - vertical overlap: {v_overlap} px \\n - horizontal overlap: {h_overlap} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68b600-7947-44d3-88df-cc87334780ff",
   "metadata": {},
   "source": [
    "## Generate Collection\n",
    "\n",
    "Each entry contains the OG file, number of tile and tile image as RGB-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9321d1d6-81d1-4731-a1dd-19c1d89db5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1133 Point Labels and 602 Shape Labels\n"
     ]
    }
   ],
   "source": [
    "point_labels = []\n",
    "shape_labels = []\n",
    "for file in labels:\n",
    "    with fiona.open(os.path.join(PATH, file)) as shapefile:\n",
    "        for feature in shapefile:\n",
    "            if feature['geometry']['type'] == \"Point\":\n",
    "                point = feature[\"geometry\"]['coordinates'][:2]\n",
    "                x = point[0]\n",
    "                y = point[1]\n",
    "                point_labels.append([Point(point), x, y])\n",
    "            elif feature['geometry']['type'] == \"Polygon\":\n",
    "                shape = feature[\"geometry\"]['coordinates'][0]\n",
    "                x_min, x_max = min(shape, key = lambda t: t[0])[0], max(shape, key = lambda t: t[0])[0]\n",
    "                y_min, y_max = min(shape, key = lambda t: t[1])[1], max(shape, key = lambda t: t[1])[1]\n",
    "                shape_labels.append([Polygon(shape), x_min, y_min, x_max, y_max])\n",
    "        \n",
    "point_labels = pd.DataFrame(data=point_labels, columns=[\"Point\", \"X\", \"Y\"])\n",
    "shape_labels = pd.DataFrame(data=shape_labels, columns=[\"Shape\", \"Xmin\", \"Ymin\", \"Xmax\", \"Ymax\"])\n",
    "print(f\"Found {len(point_labels)} Point Labels and {len(shape_labels)} Shape Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564761e-fa4c-4642-86e4-2d2f0d4af923",
   "metadata": {},
   "source": [
    "Iterate over Polygon-Shapes and assign to points that they cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2dfd4f2-b087-46ce-9c1b-8a53818ef7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in shape_labels.iterrows():\n",
    "    shape = row[\"Shape\"]\n",
    "    point_labels.loc[point_labels['Point'].apply(lambda p: p.within(shape)), \"Shape\"] = shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f230e4a-d5a4-4c7c-bcb6-f572c043e4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ec1a3ef858452ab734b4633be55423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd11c572addb44e5a6b89587753409e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a70a5d7cfa44c5aa10575358671c9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Collection of 3200 Tiles\n"
     ]
    }
   ],
   "source": [
    "collection = []\n",
    "\n",
    "for region in tqdm(regions):\n",
    "    src = rio.open(os.path.join(PATH, region))\n",
    "    name_clean = region.replace(\".tif\",\"\")\n",
    "    \n",
    "    # region as window and shapely polygon\n",
    "    ncols, nrows = src.meta['width'], src.meta['height']\n",
    "    bounds = list(src.bounds)\n",
    "    big_window = rio.windows.Window(col_off = 0, row_off = 0, width = ncols, height = nrows)\n",
    "    big_poly = Polygon([(bounds[0], bounds[1]), (bounds[2], bounds[1]), (bounds[2], bounds[3]), (bounds[0], bounds[3])])\n",
    "    \n",
    "    # filter X and Y\n",
    "    region_points = point_labels[point_labels['Point'].apply(lambda p: p.within(big_poly))].copy()\n",
    "    # region_points = point_labels[(point_labels.X > bounds[0]) & (point_labels.X < bounds[2])]\n",
    "    # region_points = region_points[(region_points.Y > bounds[1]) & (region_points.Y < bounds[3])]\n",
    "    \n",
    "    # cut shapes to region bounds\n",
    "    region_points['Shape'] = region_points['Shape'].apply(lambda s: s.intersection(big_poly) if not isinstance(s, float) else s)\n",
    "    region_points['ShapeX'] = region_points['Shape'].apply(lambda s: s.exterior.coords.xy[0] if not isinstance(s, float) else s)\n",
    "    region_points['ShapeY'] = region_points['Shape'].apply(lambda s: s.exterior.coords.xy[1] if not isinstance(s, float) else s)\n",
    "    \n",
    "    # translate to pixels\n",
    "    region_points['X'] = region_points['X'].apply(lambda x: (x - bounds[0])*8) #CHANGE\n",
    "    region_points['Y'] = region_points['Y'].apply(lambda y: (1000 - (y - bounds[1]))*8)\n",
    "    region_points['ShapeX'] = region_points['ShapeX'].apply(lambda lx: [(x - bounds[0])*8 for x in lx] if not isinstance(lx, float) else lx)\n",
    "    region_points['ShapeY'] = region_points['ShapeY'].apply(lambda ly: [(1000 - (y - bounds[1]))*8 for y in ly] if not isinstance(ly, float) else ly)\n",
    "    \n",
    "    # traverse tiles column bv column, row by row\n",
    "    for row in tqdm(range(tiles_v)):\n",
    "        row_off = int(row * (height - v_overlap))\n",
    "        for col in range(tiles_v):\n",
    "            col_off = int(col * (width - h_overlap))\n",
    "            # read tile part of region\n",
    "            window = rio.windows.Window(col_off = col_off, row_off = row_off, width = width, height = height).intersection(big_window)\n",
    "            src_image = src.read(window = window)[:3]\n",
    "            image = np.stack((src_image[0], src_image[1], src_image[2]), axis = 2)\n",
    "            # get points in tile \n",
    "            tile_points = region_points[(region_points.X > col_off) & (region_points.X < (col_off+width))]\n",
    "            tile_points = tile_points[(tile_points.Y > row_off) & (tile_points.Y < (row_off+height))]\n",
    "            # translate to new dimensions\n",
    "            tile_points['X'] = tile_points['X'].apply(lambda x: round(x - col_off))\n",
    "            tile_points['Y'] = tile_points['Y'].apply(lambda y: round(y - row_off))\n",
    "            tile_points['ShapeX'] = tile_points['ShapeX'].apply(lambda lx: [round(x - col_off) for x in lx] if not isinstance(lx, float) else lx)\n",
    "            tile_points['ShapeY'] = tile_points['ShapeY'].apply(lambda ly: [round(y - row_off) for y in ly] if not isinstance(ly, float) else ly)\n",
    "            # put shape coordinates together\n",
    "            tile_points['pShape'] = list(zip(tile_points.ShapeX, tile_points.ShapeY))\n",
    "            tile_points['pShape'] = tile_points['pShape'].apply(lambda t: list(zip(t[0], t[1])) if not isinstance(t[0], float) else float('NaN'))\n",
    "            # to Numpy\n",
    "            np_points = tile_points[['X', 'Y']].to_numpy()\n",
    "            np_shapes = tile_points['pShape'].dropna().to_numpy()\n",
    "            # add to collection\n",
    "            collection.append({\"file\": name_clean, \"tile\": str(col + (row * tiles_v) + 1), \"image\": image, \"points\": np_points, \"npoints\": len(np_points), \"shapes\": np_shapes, \"nshapes\": len(np_shapes)})\n",
    "\n",
    "collection = pd.DataFrame(collection)\n",
    "print(f\"Generated Collection of {len(collection)} Tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5e382-520e-460b-9da8-80a6077dff05",
   "metadata": {},
   "source": [
    "## Write To Data Directory\n",
    "\n",
    "Images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f750cc-631c-4e4c-92df-b78728f87073",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_TYPE = \".jpg\"\n",
    "#make new folder in data directory\n",
    "NEW_PATH = os.path.join(PATH, f\"{width}x{height}\")\n",
    "os.mkdir(NEW_PATH)\n",
    "IMAGE_PATH = os.path.join(NEW_PATH, \"images\")\n",
    "os.mkdir(IMAGE_PATH)\n",
    "\n",
    "for index, item in collection.iterrows():\n",
    "    data = item['image']\n",
    "    name = item['file'] + \"_\" + item['tile'] + TARGET_TYPE\n",
    "    #np.save(os.path.join(IMAGE_PATH, name), data) #change TARGET_TYPE\n",
    "    img = Image.fromarray(data, 'RGB')\n",
    "    img.save(os.path.join(IMAGE_PATH, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba0d81-d41f-452c-9665-bf04652fbdbe",
   "metadata": {},
   "source": [
    "Point-Labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6d2bbf-69da-4be6-acfc-237bf7bb5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PATH = os.path.join(NEW_PATH, \"points\")\n",
    "os.mkdir(LABEL_PATH)\n",
    "items_with_label = collection[collection.npoints > 0]\n",
    "for index, item in items_with_label.iterrows():\n",
    "    data = item['points']\n",
    "    name = item['file'] + \"_\" + item['tile'] + \"_points.npy\"\n",
    "    np.save(os.path.join(LABEL_PATH, name), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0700d872-e62d-4a28-91a9-0e550ac5e9c8",
   "metadata": {},
   "source": [
    "Polygon-Shapes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c0c6ab-8bb7-4b61-9907-32d496baa3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE_PATH = os.path.join(NEW_PATH, \"shapes\")\n",
    "os.mkdir(SHAPE_PATH)\n",
    "items_with_shape = collection[collection.nshapes > 0]\n",
    "for index, item in items_with_shape.iterrows():\n",
    "    data = item['shapes']\n",
    "    name = item['file'] + \"_\" + item['tile'] + \"_shapes.npy\"\n",
    "    np.save(os.path.join(SHAPE_PATH, name), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedaf8b-a06d-40fb-a3d8-b32b27165ae9",
   "metadata": {},
   "source": [
    "## Define Train, Val and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9473d973-4f57-45d8-b083-0c3e3df33640",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETS_PATH = os.path.join(NEW_PATH, \"image_sets\")\n",
    "os.mkdir(SETS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22cdb5-7c26-412a-b32e-b2614322405d",
   "metadata": {},
   "source": [
    "Filter collection to e.g. only include images in training that feature at least one point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "808501f0-aefb-419f-82f8-c4b36be3c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file = open(os.path.join(SETS_PATH, \"all.txt\"), \"w\")\n",
    "points_file = open(os.path.join(SETS_PATH, \"points.txt\"), \"w\") \n",
    "shapes_file = open(os.path.join(SETS_PATH, \"shapes.txt\"), \"w\") \n",
    "\n",
    "for index, item in collection.iterrows():\n",
    "    name = item['file'] + \"_\" + item['tile'] + \"\\n\"\n",
    "    all_file.write(name)\n",
    "    if item.nshapes > 0:\n",
    "        shapes_file.write(name)\n",
    "    if item.npoints > 0:\n",
    "        points_file.write(name) \n",
    "\n",
    "all_file.close() \n",
    "points_file.close()     \n",
    "shapes_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468e4fe-c9d0-4fa9-8703-07f01d398f5c",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAL ORIENTED BOUNDARIES\n",
    "\n",
    "Generates COB-Images for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a89224df-c66b-4e42-b650-8a3d9eabcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.io import imread\n",
    "from imgaug import augmenters as iaa\n",
    "from models.base.cobnet import CobNet\n",
    "from imgaug.augmenters import Augmenter\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from helpers.cob.dataset import rescale_augmenter, Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed5698-51bf-4995-97ff-300caebe183a",
   "metadata": {},
   "source": [
    "## Enter Settings and Search Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45e86357-dbfe-4745-a6d4-55afa512f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/jovyan/work/DENMARK/256x256\"\n",
    "IMAGES_PATH = os.path.join(PATH, \"images\")\n",
    "SAVE_PATH = os.path.join(PATH, \"cob\")\n",
    "\n",
    "TYPE = \".jpg\"\n",
    "IMAGE_WIDTH = 256\n",
    "STATE_DICT = \"/home/jovyan/work/runs/COBNET/cp_or.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84f1cdee-8c94-4acb-b501-fbd9f55da165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "for _, _, files in os.walk(IMAGES_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(TYPE):\n",
    "            images.append(file)\n",
    "\n",
    "n_images = len(images)\n",
    "print(f\"Found {n_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad60d24-1937-45b3-b851-8045be88b832",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25cef416-b3c5-4ce7-9b26-45d7d4bd5073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1b28752898461ea6320c21a96b2d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_normalized = []\n",
    "\n",
    "normalization_mean = [0.492, 0.475, 0.430]\n",
    "normalization_std= [0.176, 0.173, 0.176]\n",
    "\n",
    "aug = iaa.Sequential([\n",
    "    iaa.size.Resize(IMAGE_WIDTH),\n",
    "    rescale_augmenter,\n",
    "    Normalize(mean = normalization_mean, std = normalization_std)\n",
    "])\n",
    "\n",
    "aug_det = aug.to_deterministic()\n",
    "\n",
    "for i in tqdm(range(n_images)):\n",
    "    image = imread(os.path.join(IMAGES_PATH, images[i]))\n",
    "    image = aug_det(images = image[np.newaxis, ...])[0]\n",
    "    image = np.stack((image[:,:,0], image[:,:,1], image[:,:,2]), axis = 0)\n",
    "    #image = image[np.newaxis, ...] either create batch axis here, at tensor creation or use batches\n",
    "    images_normalized.append(image)\n",
    "\n",
    "#batch = np.stack(img_collection, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b2ffa-1c4b-4380-b0bb-a9a10c571ebd",
   "metadata": {},
   "source": [
    "## COB Model Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f073fcd6-480f-4a60-85ce-97c4bbbb5332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f336f3acd454d9cb6d1bcac8e13c1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3200 COB images.\n"
     ]
    }
   ],
   "source": [
    "cob_collection = []\n",
    "\n",
    "model = CobNet()\n",
    "model.load_state_dict(torch.load(STATE_DICT))\n",
    "\n",
    "for image in tqdm(images_normalized):\n",
    "    img_tensor = torch.tensor(image[np.newaxis, ...]).float()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cob = model(img_tensor)\n",
    "    cob_collection.append(cob)\n",
    "    \n",
    "print(f\"Generated {len(cob_collection)} COB images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2116599-743f-42b5-940d-0a672a1a294b",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a19570-9d93-4eee-b420-7d5453979b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(SAVE_PATH) # comment out if existing\n",
    "cob_file = open(os.path.join(PATH, \"image_sets\", \"cob.txt\"), \"w\")\n",
    "\n",
    "for i in range(len(cob_collection)):\n",
    "    data = cob_collection[i]['y_fine'].sigmoid()\n",
    "    path = os.path.join(SAVE_PATH, images[i])\n",
    "    cob_file.write(name) \n",
    "    save_image(data, path)\n",
    "    \n",
    "cob_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7736f7-3955-468e-83f5-f99306e67e72",
   "metadata": {},
   "source": [
    "# EXPLORATION ZONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fd185-a2bf-4fa3-b1d7-e10be27d5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many 250x250 tiles actually have a label?\n",
    "have = len(collection[collection.npoints > 0])\n",
    "total = len(collection)\n",
    "print(f\"From a total of {total} tiles, {have} have a label assigned ({have/total*100} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349aaff-7ad6-437a-8daf-a4f23fe4ca23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
