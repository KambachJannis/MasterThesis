{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b09563f-8a29-483d-9664-280c0d6b1de7",
   "metadata": {},
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "The purpose of this Notebook is to split all 1km x 1km regions stored as .tif-files into smaller tiles that are suitable as network inputs. Tiles will be saved as .jpg-images in a new folder along with point-labels and shape-labels as .npy-files.\n",
    "\n",
    "The final structure of the output folder will look like this:\n",
    "\n",
    "Folder name: **512x512** (width x hight of tiles) \n",
    "- **images**: contains individual tiles as .jpg-images with name {region name} _ {tile number}.jpg \n",
    "- **points_trees / points_trees**: point-labels as .npy-files, matched via filename\n",
    "- **shapes_trees / shapes_buildings**: shape-labels as .npy-files, matched via filename\n",
    "- **image_sets_trees / image_sets_buildings**: contains a .txt-file for each split (train, val, test) with the filenames of the assigned tiles\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fe04f-b812-4510-8c35-853d70215e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import fiona\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import rasterio as rio\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bad5f5-3e52-4db1-a5a5-c142b204cf6d",
   "metadata": {},
   "source": [
    "## Get all Images and Label-Files from Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910883d4-089f-4e40-9050-8006e906894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/jovyan/work/satellite_data/jannis/Denmark SDFE\"\n",
    "SAVE_PATH = \"/home/jovyan/work/processed\"\n",
    "\n",
    "IMAGES_DIR = \"normal_orto\"\n",
    "IMAGETYPE = \".tif\"\n",
    "\n",
    "regions = []\n",
    "PATH = os.path.join(DATA_PATH, IMAGES_DIR)\n",
    "for _, _, files in os.walk(PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(IMAGETYPE):\n",
    "            regions.append(file)\n",
    "            \n",
    "DATA_TREES_POINTS = \"trees_vector/85blocks_trees.shp\"\n",
    "DATA_TREES_SHAPES = \"/home/jovyan/work/mydata/DENMARK/85blocks_trees_shapes.shp\"\n",
    "DATA_BUILDINGS = \"buildings_vector/bygninger_2017_uden_kolonihavn.shp\"\n",
    "labels = [os.path.join(DATA_PATH, DATA_TREES_POINTS), DATA_TREES_SHAPES]\n",
    "            \n",
    "print(f\"Found {len(regions)} Regions and {len(labels)} Label-Files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943eb38-f248-47b8-8130-9d18012b51e4",
   "metadata": {},
   "source": [
    "## Set Tile Size and Overlap\n",
    "\n",
    "To ensure equal tile sizes, overap is computed dynamically based on the amount of vertical and horizontal tiles. When executing this cell, make sure that a number of tiles is selected, that ensures sufficient overlap between the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0756c-183d-46ba-a8ab-7ef735357e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_h = 40\n",
    "tiles_v = 40\n",
    "width = 256\n",
    "height = 256\n",
    "\n",
    "example_src = rio.open(os.path.join(PATH, regions[0]))\n",
    "ncols, nrows = example_src.meta['width'], example_src.meta['height']\n",
    "h_overlap = ((tiles_h * width) - ncols) / (tiles_h - 1)\n",
    "v_overlap = ((tiles_v * height) - nrows) / (tiles_v - 1)\n",
    "\n",
    "print(f\"Generating {tiles_h * tiles_v} tiles per region with: \\n - tile size: {width} x {height} px \\n - region size: {ncols} x {nrows} px \\n - vertical overlap: {v_overlap} px \\n - horizontal overlap: {h_overlap} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68b600-7947-44d3-88df-cc87334780ff",
   "metadata": {},
   "source": [
    "## Load Shapes and Points\n",
    "\n",
    "Fiona loads shapefile data and groups points and polygons into two separate dataframes. Dataframes are used due to their built-in efficient selection and function-application methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321d1d6-81d1-4731-a1dd-19c1d89db5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_labels = []\n",
    "shape_labels = []\n",
    "for file in labels:\n",
    "    with fiona.open(file) as shapefile:\n",
    "        for feature in tqdm(shapefile):\n",
    "            if feature['geometry']['type'] == \"Point\":\n",
    "                point = feature[\"geometry\"]['coordinates'][:2]\n",
    "                x = point[0]\n",
    "                y = point[1]\n",
    "                point_labels.append([Point(point), x, y])\n",
    "            elif feature['geometry']['type'] == \"Polygon\":\n",
    "                shape = feature[\"geometry\"]['coordinates'][0]\n",
    "                poly = Polygon(shape)\n",
    "                shape_labels.append([poly])\n",
    "        \n",
    "point_labels = pd.DataFrame(data=point_labels, columns=[\"Point\", \"X\", \"Y\"])\n",
    "shape_labels = pd.DataFrame(data=shape_labels, columns=[\"Shape\"])\n",
    "print(f\"Found {len(point_labels)} Point Labels and {len(shape_labels)} Shape Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5bd51-25f4-4ff7-8dbc-360bdcd1cbc8",
   "metadata": {},
   "source": [
    "## Collection Generator FOR TREES\n",
    "\n",
    "The outer loop iterates over the different regions, the inner loop constructs the tiles. Tiles are saved as a dictionary to a list. Checkpoints are saved every 10 regions so that the list can be cleared - this checkpoint interval can be tuned according to the available memory.\n",
    "\n",
    "Both shapes and points dataframe need to be filled for this cell to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f230e4a-d5a4-4c7c-bcb6-f572c043e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []\n",
    "counter = 0\n",
    "checkpoint = 10\n",
    "\n",
    "for region in tqdm(regions):\n",
    "    src = rio.open(os.path.join(PATH, region))\n",
    "    name_clean = region.replace(\".tif\",\"\")\n",
    "    \n",
    "    # region as window and shapely polygon\n",
    "    ncols, nrows = src.meta['width'], src.meta['height']\n",
    "    bounds = list(src.bounds)\n",
    "    big_window = rio.windows.Window(col_off = 0, row_off = 0, width = ncols, height = nrows)\n",
    "    big_poly = Polygon([(bounds[0], bounds[1]), (bounds[2], bounds[1]), (bounds[2], bounds[3]), (bounds[0], bounds[3])])\n",
    "    \n",
    "    # filter X and Y\n",
    "    region_points = point_labels[point_labels['Point'].apply(lambda p: p.within(big_poly))].copy()\n",
    "    region_shapes = shape_labels[shape_labels['Shape'].apply(lambda s: s.intersects(big_poly))].copy()\n",
    "    \n",
    "    # cut shapes to region bounds\n",
    "    region_shapes['Shape'] = region_shapes['Shape'].apply(lambda s: s.intersection(big_poly))\n",
    "    region_shapes['Shape'] = region_shapes['Shape'].apply(lambda s: s if s.geom_type != 'MultiPolygon' else list(s))\n",
    "    region_shapes = region_shapes.explode('Shape')\n",
    "    region_shapes['Type'] = region_shapes['Shape'].apply(lambda s: s.geom_type)\n",
    "    region_shapes = region_shapes[region_shapes['Type'] == 'Polygon']\n",
    "    region_shapes['ShapeX'] = region_shapes['Shape'].apply(lambda s: s.exterior.coords.xy[0])\n",
    "    region_shapes['ShapeY'] = region_shapes['Shape'].apply(lambda s: s.exterior.coords.xy[1])\n",
    "    \n",
    "    # translate to pixels\n",
    "    region_points['X'] = region_points['X'].apply(lambda x: (x - bounds[0])*8)\n",
    "    region_points['Y'] = region_points['Y'].apply(lambda y: (1000 - (y - bounds[1]))*8)\n",
    "    region_points['Point'] = list(zip(region_points.X, region_points.Y))\n",
    "    region_shapes['ShapeX'] = region_shapes['ShapeX'].apply(lambda lx: [(x - bounds[0])*8 for x in lx])\n",
    "    region_shapes['ShapeY'] = region_shapes['ShapeY'].apply(lambda ly: [(1000 - (y - bounds[1]))*8 for y in ly])\n",
    "    region_shapes['Shape'] = list(zip(region_shapes.ShapeX, region_shapes.ShapeY))\n",
    "    region_shapes['Shape'] = region_shapes['Shape'].apply(lambda t: list(zip(t[0], t[1])))\n",
    "    \n",
    "    # traverse tiles column bv column, row by row\n",
    "    for row in tqdm(range(tiles_v)):\n",
    "        row_off = int(row * (height - v_overlap))\n",
    "        for col in range(tiles_v):\n",
    "            col_off = int(col * (width - h_overlap))\n",
    "            # define tile bounds\n",
    "            tile_window = rio.windows.Window(col_off = col_off, row_off = row_off, width = width, height = height).intersection(big_window)\n",
    "            tile_poly = Polygon([(col_off, row_off), (col_off+width, row_off), (col_off+width, row_off+height), (col_off, row_off+height)])\n",
    "            # read image\n",
    "            src_image = src.read(window = tile_window)[:3]\n",
    "            image = np.stack((src_image[0], src_image[1], src_image[2]), axis = 2)\n",
    "            # get points and shapes in tile \n",
    "            tile_points = region_points[region_points['Point'].apply(lambda p: Point(p).within(tile_poly))].copy()\n",
    "            tile_shapes = region_shapes[region_shapes['Shape'].apply(lambda s: Polygon(s).intersects(tile_poly))].copy()\n",
    "            #cut to tile bounds\n",
    "            if not tile_shapes.empty:\n",
    "                tile_shapes['Shape'] = tile_shapes['Shape'].apply(lambda s: Polygon(s).intersection(tile_poly))\n",
    "                tile_shapes['Shape'] = tile_shapes['Shape'].apply(lambda s: s if s.geom_type != 'MultiPolygon' else list(s))\n",
    "                tile_shapes = tile_shapes.explode('Shape')\n",
    "                tile_shapes['Type'] = tile_shapes['Shape'].apply(lambda s: s.geom_type)\n",
    "                tile_shapes = tile_shapes[tile_shapes['Type'] == 'Polygon']\n",
    "                tile_shapes['ShapeX'] = tile_shapes['Shape'].apply(lambda s: s.exterior.coords.xy[0])\n",
    "                tile_shapes['ShapeY'] = tile_shapes['Shape'].apply(lambda s: s.exterior.coords.xy[1])\n",
    "                # translate to new dimensions\n",
    "                tile_shapes['ShapeX'] = tile_shapes['ShapeX'].apply(lambda lx: [round(x - col_off) for x in lx])\n",
    "                tile_shapes['ShapeY'] = tile_shapes['ShapeY'].apply(lambda ly: [round(y - row_off) for y in ly])\n",
    "                # put shape coordinates together\n",
    "                tile_shapes['pShape'] = list(zip(tile_shapes.ShapeX, tile_shapes.ShapeY))\n",
    "                tile_shapes['pShape'] = tile_shapes['pShape'].apply(lambda t: list(zip(t[0], t[1])))\n",
    "                # to Numpy\n",
    "                np_shapes = tile_shapes['pShape'].to_numpy()\n",
    "            else:\n",
    "                np_shapes = tile_shapes.to_numpy()\n",
    "            \n",
    "            if not tile_points.empty: \n",
    "                # translate to new dimensions\n",
    "                tile_points['X'] = tile_points['X'].apply(lambda x: round(x - col_off))\n",
    "                tile_points['Y'] = tile_points['Y'].apply(lambda y: round(y - row_off))\n",
    "                # to Numpy\n",
    "                np_points = tile_points[['X', 'Y']].to_numpy()\n",
    "            else:\n",
    "                # check if there is still a shape in this tile - if that is the case, we need to make up a new point\n",
    "                if not tile_shapes.empty:\n",
    "                    tile_points['Point'] = tile_shapes['pShape'].apply(lambda t: Polygon(t).representative_point())\n",
    "                    tile_points['X'] = tile_points['Point'].apply(lambda p: round(list(p.coords)[0][0]))\n",
    "                    tile_points['Y'] = tile_points['Point'].apply(lambda p: round(list(p.coords)[0][1]))\n",
    "                    # to Numpy\n",
    "                    np_points = tile_points[['X', 'Y']].to_numpy()\n",
    "                else:\n",
    "                    np_points = tile_points.to_numpy()\n",
    "            \n",
    "            if not tile_shapes.empty and tile_points.empty:\n",
    "                raise ValueError(\"trying to create a tile with polygons but no points\")\n",
    "            # add to collection\n",
    "            collection.append({\"file\": name_clean, \"tile\": str(col + (row * tiles_v) + 1), \"image\": image, \"points\": np_points, \"npoints\": len(np_points), \"shapes\": np_shapes, \"nshapes\": len(np_shapes)})\n",
    "            \n",
    "    if counter != 0 and counter % checkpoint == 0 :\n",
    "        print(f\"Saving checkpoint at {counter}\")\n",
    "        np.save(os.path.join(SAVE_PATH, \"checkpoint_\"+str(counter)), collection)\n",
    "        collection = []\n",
    "        \n",
    "    counter += 1\n",
    "\n",
    "np.save(os.path.join(SAVE_PATH, \"checkpoint_\"+str(counter)), collection)\n",
    "print(f\"Generated Collection...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd4b910-b4dc-4f48-a43a-04f7db7b4d72",
   "metadata": {},
   "source": [
    "## Collection Generator FOR BUILDINGS\n",
    "\n",
    "This cell differs from the previous one in that point-labels are not loaded from the dataframe above but inferred as reference points from the shapes. Output is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c7cd5-209f-44cc-9ee3-c2bda3442f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []\n",
    "counter = 0\n",
    "checkpoint = 10\n",
    "\n",
    "for region in tqdm(regions):\n",
    "    src = rio.open(os.path.join(PATH, region))\n",
    "    name_clean = region.replace(\".tif\",\"\")\n",
    "    \n",
    "    # region as window and shapely polygon\n",
    "    ncols, nrows = src.meta['width'], src.meta['height']\n",
    "    bounds = list(src.bounds)\n",
    "    big_window = rio.windows.Window(col_off = 0, row_off = 0, width = ncols, height = nrows)\n",
    "    big_poly = Polygon([(bounds[0], bounds[1]), (bounds[2], bounds[1]), (bounds[2], bounds[3]), (bounds[0], bounds[3])])\n",
    "    \n",
    "    # filter X and Y\n",
    "    region_shapes = shape_labels[shape_labels['Shape'].apply(lambda s: s.intersects(big_poly))].copy()\n",
    "    \n",
    "    # cut shapes to region bounds\n",
    "    region_shapes['Shape'] = region_shapes['Shape'].apply(lambda s: s.intersection(big_poly))\n",
    "    region_shapes['Shape'] = region_shapes['Shape'].apply(lambda s: s if s.geom_type != 'MultiPolygon' else list(s))\n",
    "    region_shapes = region_shapes.explode('Shape')\n",
    "    region_shapes['Type'] = region_shapes['Shape'].apply(lambda s: s.geom_type)\n",
    "    region_shapes = region_shapes[region_shapes['Type'] == 'Polygon']\n",
    "    region_shapes['ShapeX'] = region_shapes['Shape'].apply(lambda s: s.exterior.coords.xy[0])\n",
    "    region_shapes['ShapeY'] = region_shapes['Shape'].apply(lambda s: s.exterior.coords.xy[1])\n",
    "    \n",
    "    # translate to pixels\n",
    "    region_shapes['ShapeX'] = region_shapes['ShapeX'].apply(lambda lx: [(x - bounds[0])*8 for x in lx])\n",
    "    region_shapes['ShapeY'] = region_shapes['ShapeY'].apply(lambda ly: [(1000 - (y - bounds[1]))*8 for y in ly])\n",
    "    region_shapes['Shape'] = list(zip(region_shapes.ShapeX, region_shapes.ShapeY))\n",
    "    region_shapes['Shape'] = region_shapes['Shape'].apply(lambda t: list(zip(t[0], t[1])))\n",
    "    \n",
    "    # traverse tiles column bv column, row by row\n",
    "    for row in tqdm(range(tiles_v)):\n",
    "        row_off = int(row * (height - v_overlap))\n",
    "        for col in range(tiles_v):\n",
    "            col_off = int(col * (width - h_overlap))\n",
    "            # define tile bounds\n",
    "            tile_window = rio.windows.Window(col_off = col_off, row_off = row_off, width = width, height = height).intersection(big_window)\n",
    "            tile_poly = Polygon([(col_off, row_off), (col_off+width, row_off), (col_off+width, row_off+height), (col_off, row_off+height)])\n",
    "            # read image\n",
    "            src_image = src.read(window = tile_window)[:3]\n",
    "            image = np.stack((src_image[0], src_image[1], src_image[2]), axis = 2)\n",
    "            # get points and shapes in tile \n",
    "            tile_shapes = region_shapes[region_shapes['Shape'].apply(lambda s: Polygon(s).intersects(tile_poly))].copy()\n",
    "            #cut to tile bounds\n",
    "            tile_shapes['Shape'] = tile_shapes['Shape'].apply(lambda s: Polygon(s).intersection(tile_poly))\n",
    "            tile_shapes['Shape'] = tile_shapes['Shape'].apply(lambda s: s if s.geom_type != 'MultiPolygon' else list(s))\n",
    "            tile_shapes = tile_shapes.explode('Shape')\n",
    "            tile_shapes['Type'] = tile_shapes['Shape'].apply(lambda s: s.geom_type)\n",
    "            tile_shapes = tile_shapes[tile_shapes['Type'] == 'Polygon']\n",
    "            tile_shapes['ShapeX'] = tile_shapes['Shape'].apply(lambda s: s.exterior.coords.xy[0])\n",
    "            tile_shapes['ShapeY'] = tile_shapes['Shape'].apply(lambda s: s.exterior.coords.xy[1])\n",
    "            # translate to new dimensions\n",
    "            tile_shapes['ShapeX'] = tile_shapes['ShapeX'].apply(lambda lx: [round(x - col_off) for x in lx])\n",
    "            tile_shapes['ShapeY'] = tile_shapes['ShapeY'].apply(lambda ly: [round(y - row_off) for y in ly])\n",
    "            # put shape coordinates together\n",
    "            tile_shapes['pShape'] = list(zip(tile_shapes.ShapeX, tile_shapes.ShapeY))\n",
    "            tile_shapes['pShape'] = tile_shapes['pShape'].apply(lambda t: list(zip(t[0], t[1])))\n",
    "            #get representative point\n",
    "            tile_shapes['Point'] = tile_shapes['pShape'].apply(lambda t: Polygon(t).representative_point())\n",
    "            tile_shapes['PointX'] = tile_shapes['Point'].apply(lambda p: round(list(p.coords)[0][0]))\n",
    "            tile_shapes['PointY'] = tile_shapes['Point'].apply(lambda p: round(list(p.coords)[0][1]))\n",
    "            # to Numpy\n",
    "            np_points = tile_shapes[['PointX', 'PointY']].to_numpy()\n",
    "            np_shapes = tile_shapes['pShape'].to_numpy()\n",
    "            # add to collection\n",
    "            collection.append({\"file\": name_clean, \"tile\": str(col + (row * tiles_v) + 1), \"image\": image, \"points\": np_points, \"npoints\": len(np_points), \"shapes\": np_shapes, \"nshapes\": len(np_shapes)})\n",
    "            \n",
    "    if counter != 0 and counter % checkpoint == 0 :\n",
    "        print(f\"Saving checkpoint at {counter}\")\n",
    "        np.save(os.path.join(SAVE_PATH, \"checkpoint_\"+str(counter)), collection)\n",
    "        collection = []\n",
    "        \n",
    "    counter += 1\n",
    "\n",
    "np.save(os.path.join(SAVE_PATH, \"checkpoint_\"+str(counter)), collection)\n",
    "print(f\"Generated Collection...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5e382-520e-460b-9da8-80a6077dff05",
   "metadata": {},
   "source": [
    "## Write To Data Directory\n",
    "\n",
    "First cell creates the necessary directories, remaining cells need to be executed for each checkpoint file.\n",
    "\n",
    "Remember to choose the right write mode for the text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e86b6-3c1e-4012-bcd7-184b9f805a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_PATH = os.path.join(SAVE_PATH, f\"{width}x{height}\")\n",
    "#os.mkdir(NEW_PATH)\n",
    "IMAGE_PATH = os.path.join(NEW_PATH, \"images\")\n",
    "#os.mkdir(IMAGE_PATH)\n",
    "LABEL_PATH = os.path.join(NEW_PATH, \"points_trees\") #points_buildings\n",
    "os.mkdir(LABEL_PATH)\n",
    "SHAPE_PATH = os.path.join(NEW_PATH, \"shapes_trees\") #shapes_buildings\n",
    "#os.mkdir(SHAPE_PATH)\n",
    "SETS_PATH = os.path.join(NEW_PATH, \"image_sets_trees\") #image_sets_buildings\n",
    "#os.mkdir(SETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39eb82-8d75-448b-9b3d-f3578900adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"checkpoint_85.npy\"\n",
    "collection = np.load(os.path.join(SAVE_PATH, file), allow_pickle=True)\n",
    "collection = pd.DataFrame(collection)\n",
    "collection = collection[0].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efcc10-6e3e-4707-8730-adf856a0e9ac",
   "metadata": {},
   "source": [
    "Images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f750cc-631c-4e4c-92df-b78728f87073",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_TYPE = \".jpg\"\n",
    "\n",
    "for index, item in tqdm(collection.iterrows()):\n",
    "    data = item['image']\n",
    "    name = item['file'] + \"_\" + item['tile'] + TARGET_TYPE\n",
    "    #np.save(os.path.join(IMAGE_PATH, name), data) #change TARGET_TYPE\n",
    "    img = Image.fromarray(data, 'RGB')\n",
    "    img.save(os.path.join(IMAGE_PATH, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba0d81-d41f-452c-9665-bf04652fbdbe",
   "metadata": {},
   "source": [
    "Point-Labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d2bbf-69da-4be6-acfc-237bf7bb5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_with_label = collection[collection.npoints > 0]\n",
    "\n",
    "for index, item in tqdm(items_with_label.iterrows()):\n",
    "    data = item['points']\n",
    "    name = item['file'] + \"_\" + item['tile'] + \"_points.npy\"\n",
    "    np.save(os.path.join(LABEL_PATH, name), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0700d872-e62d-4a28-91a9-0e550ac5e9c8",
   "metadata": {},
   "source": [
    "Polygon-Shapes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0c6ab-8bb7-4b61-9907-32d496baa3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_with_shape = collection[collection.nshapes > 0]\n",
    "\n",
    "for index, item in tqdm(items_with_shape.iterrows()):\n",
    "    data = item['shapes']\n",
    "    name = item['file'] + \"_\" + item['tile'] + \"_shapes.npy\"\n",
    "    np.save(os.path.join(SHAPE_PATH, name), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedaf8b-a06d-40fb-a3d8-b32b27165ae9",
   "metadata": {},
   "source": [
    "Create text-files containing the names of all tiles, those containing points and those containing shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808501f0-aefb-419f-82f8-c4b36be3c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"a\" #\"w\" for write\n",
    "#all_file = open(os.path.join(SETS_PATH, \"all.txt\"), mode)\n",
    "points_file = open(os.path.join(SETS_PATH, \"points.txt\"), mode) \n",
    "#shapes_file = open(os.path.join(SETS_PATH, \"shapes.txt\"), mode) \n",
    "\n",
    "for index, item in collection.iterrows():\n",
    "    name = item['file'] + \"_\" + item['tile'] + \"\\n\"\n",
    "    #all_file.write(name)\n",
    "    #if item.nshapes > 0:\n",
    "        #shapes_file.write(name)\n",
    "    if item.npoints > 0:\n",
    "        points_file.write(name) \n",
    "\n",
    "#all_file.close() \n",
    "points_file.close()     \n",
    "#shapes_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ea10b-650d-4a32-8988-7b93aac43c14",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "# IMAGE NORMALIZATION\n",
    "\n",
    "These cells may be used to a large amount of images in order to determine means and standard deviations for image normalization during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87f1dd-1197-488a-b3f2-c3d9bb778c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "from helpers import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18716e-1cec-48c7-916f-d51c9ac5ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/jovyan/work/DENMARK/256x256\"\n",
    "images_path = os.paths.join(DATA_PATH, \"image_sets\", \"all.txt\")\n",
    "images = [name.replace(\"\\n\",\"\") for name in io.readText(images_path)]\n",
    "\n",
    "dataset = datasets.getDataset(name = \"denmark_points\", \n",
    "                              path = DATA_PATH,\n",
    "                              images = images,\n",
    "                              n_classes = 2,\n",
    "                              transform = None)\n",
    "\n",
    "sampler = torch.utils.data.RandomSampler(dataset)\n",
    "loader = DataLoader(dataset, sampler = sampler, batch_size = len(dataset), drop_last = True, num_workers = 1)\n",
    "\n",
    "dataiter = iter(loader)\n",
    "batch = dataiter.next()\n",
    "\n",
    "print(np.mean(batch['images'].numpy(), axis = (0, 2, 3)), \"\\n\", np.std(batch['images'].numpy(), axis = (0, 2, 3)))\n",
    "#print(np.mean(batch['images'].numpy()), \"\\n\", np.std(batch['images'].numpy())) sanity check without axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468e4fe-c9d0-4fa9-8703-07f01d398f5c",
   "metadata": {},
   "source": [
    "-------------------\n",
    "# CONVOLUTIONAL ORIENTED BOUNDARIES\n",
    "\n",
    "Generates COB-Images for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89224df-c66b-4e42-b650-8a3d9eabcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.io import imread\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from models.cobnet import COBNet\n",
    "from helpers.cob.dataset import COBtransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed5698-51bf-4995-97ff-300caebe183a",
   "metadata": {},
   "source": [
    "## Enter Settings and Search Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e86357-dbfe-4745-a6d4-55afa512f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/jovyan/work/processed/256x256\"\n",
    "IMAGES_PATH = os.path.join(PATH, \"images\")\n",
    "SAVE_PATH = os.path.join(PATH, \"cob\")\n",
    "#os.mkdir(SAVE_PATH)\n",
    "\n",
    "TYPE = \".jpg\"\n",
    "IMAGE_WIDTH = 256\n",
    "STATE_DICT = \"/home/jovyan/work/runs/X_COBNET/cp_or.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f1cdee-8c94-4acb-b501-fbd9f55da165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136000 images\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "for _, _, files in os.walk(IMAGES_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(TYPE):\n",
    "            images.append(file)\n",
    "\n",
    "n_images = len(images)\n",
    "print(f\"Found {n_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad60d24-1937-45b3-b851-8045be88b832",
   "metadata": {},
   "source": [
    "## Normalize and Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cef416-b3c5-4ce7-9b26-45d7d4bd5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [0.492, 0.475, 0.430]\n",
    "stds = [0.176, 0.173, 0.176]\n",
    "transform = COBtransform(means, stds, IMAGE_WIDTH)\n",
    "\n",
    "model = COBNet()\n",
    "model.load_state_dict(torch.load(STATE_DICT))\n",
    "\n",
    "for i in tqdm(range(n_images)):\n",
    "    image = imread(os.path.join(IMAGES_PATH, images[i]))\n",
    "    image = transform(images = image[np.newaxis, ...])[0]\n",
    "    image = np.stack((image[:,:,0], image[:,:,1], image[:,:,2]), axis = 0)\n",
    "    img_tensor = torch.tensor(image[np.newaxis, ...]).float()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cob = model(img_tensor)\n",
    "        \n",
    "    data = cob['y_fine'].sigmoid()\n",
    "    path = os.path.join(SAVE_PATH, images[i])\n",
    "    save_image(data, path)\n",
    "    \n",
    "print(\"Generated all images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c35c3e-9062-42a6-b4aa-ae7578ba6ec7",
   "metadata": {},
   "source": [
    "---------\n",
    "# MODEL OUTPUT GENERATOR\n",
    "\n",
    "Intended to generate model outputs for large amounts of images to avoid forward model processing in hybrid approach and be able to cache data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1ed20-eca9-4d26-a9c0-04506d9a0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from skimage.morphology import label as ski_label\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453a77e-d593-402f-85f1-a403bbf48524",
   "metadata": {},
   "source": [
    "## Enter Settings and Search Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f07b5a-6207-47ff-a410-7592fb42d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/jovyan/work/processed/256x256\"\n",
    "IMAGES_PATH = os.path.join(PATH, \"images\")\n",
    "SAVE_PATH = os.path.join(PATH, \"model-output\")\n",
    "os.mkdir(SAVE_PATH)\n",
    "\n",
    "TYPE = \".jpg\"\n",
    "IMAGE_WIDTH = 256\n",
    "\n",
    "NET_NAME = 'vgg16'\n",
    "N_CLASSES = 2\n",
    "CHECKPOINT = \"/home/jovyan/work/runs/buildings_points_final/checkpoint_best.pth\"\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449bb7a-a22b-4293-b295-cc927e43e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for _, _, files in os.walk(IMAGES_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(TYPE):\n",
    "            images.append(file)\n",
    "\n",
    "n_images = len(images)\n",
    "print(f\"Found {n_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece829e-0dd2-4fcd-ba8a-c7b6de839498",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07c25d-7642-4f77-a3fc-232e15f26a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_mean = [0.492, 0.475, 0.430]\n",
    "transform_std = [0.176, 0.173, 0.176]\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = transform_mean, \n",
    "                                                     std = transform_std)])\n",
    "\n",
    "model = models.getNet(NET_NAME, N_CLASSES).cuda()\n",
    "model.load_state_dict(torch.load(CHECKPOINT)['model'])\n",
    "\n",
    "for i in tqdm(range(n_images)):\n",
    "    image = imread(os.path.join(IMAGES_PATH, images[i]))\n",
    "    image = transform(image)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model.forward(image.cuda())\n",
    "        \n",
    "    probs = out.sigmoid().cpu().detach().numpy()\n",
    "    blobs = ski_label((probs > THRESHOLD).astype('uint8') == 1)\n",
    "    \n",
    "    path = os.path.join(SAVE_PATH, images[i])\n",
    "    save_image(blobs, path)\n",
    "    \n",
    "print(\"Generated all images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7736f7-3955-468e-83f5-f99306e67e72",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "# EXPLORATION REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a19570-9d93-4eee-b420-7d5453979b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(SAVE_PATH) # comment out if existing\n",
    "cob_file = open(os.path.join(PATH, \"image_sets\", \"cob.txt\"), \"w\")\n",
    "\n",
    "for i in range(len(cob_collection)):\n",
    "    data = cob_collection[i]['y_fine'].sigmoid()\n",
    "    path = os.path.join(SAVE_PATH, images[i])\n",
    "    cob_file.write(name) \n",
    "    save_image(data, path)\n",
    "    \n",
    "cob_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fd185-a2bf-4fa3-b1d7-e10be27d5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many 250x250 tiles actually have a label?\n",
    "have = len(collection[collection.npoints > 0])\n",
    "total = len(collection)\n",
    "print(f\"From a total of {total} tiles, {have} have a label assigned ({have/total*100} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebab879c-1ff7-4ac1-96d0-f9676d583ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [x[:-4] for x in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93c53349-f9e2-42c3-a0b0-b18d4fbf54f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21201\n"
     ]
    }
   ],
   "source": [
    "labels_t = []\n",
    "for image in images:\n",
    "    path = os.path.join(\"/home/jovyan/work/processed/256x256/points_trees\", image+\"_points.npy\")\n",
    "    if os.path.isfile(path):\n",
    "        points = np.load(path)\n",
    "        labels_t.append(len(points))\n",
    "    else:\n",
    "        pass\n",
    "print(len(labels_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260548d8-6777-434d-8b2f-3e0e9aea44e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
