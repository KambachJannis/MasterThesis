{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946fe04f-b812-4510-8c35-853d70215e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fiona\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import rasterio as rio\n",
    "from helpers import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bad5f5-3e52-4db1-a5a5-c142b204cf6d",
   "metadata": {},
   "source": [
    "## Get all Images and Label-Files from Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910883d4-089f-4e40-9050-8006e906894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 Regions and 2 Label-Files\n"
     ]
    }
   ],
   "source": [
    "DATADIR = \"/home/jovyan/work\"\n",
    "DATASET = \"DENMARK\"\n",
    "IMAGETYPE = \".tif\"\n",
    "LABELTYPE = \".shp\"\n",
    "\n",
    "regions = []\n",
    "labels = []\n",
    "PATH = os.path.join(DATADIR, DATASET)\n",
    "for _, _, files in os.walk(PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(IMAGETYPE):\n",
    "            regions.append(file)\n",
    "        elif file.endswith(LABELTYPE):\n",
    "            labels.append(file)\n",
    "            \n",
    "print(f\"Found {len(regions)} Regions and {len(labels)} Label-Files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943eb38-f248-47b8-8130-9d18012b51e4",
   "metadata": {},
   "source": [
    "## Set Tile Size and Overlap\n",
    "\n",
    "To ensure equal tile sizes, overap is computed dynamically based on the amount of vertical and horizontal tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f0756c-183d-46ba-a8ab-7ef735357e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1600 tiles per region with: \n",
      " - tile size: 250 x 250 px \n",
      " - region size: 8000 x 8000 px \n",
      " - vertical overlap: 51.282051282051285 px \n",
      " - horizontal overlap: 51.282051282051285 px\n"
     ]
    }
   ],
   "source": [
    "tiles_h = 40\n",
    "tiles_v = 40\n",
    "width = 250\n",
    "height = 250\n",
    "\n",
    "example_src = rio.open(os.path.join(PATH, regions[0]))\n",
    "ncols, nrows = example_src.meta['width'], example_src.meta['height']\n",
    "h_overlap = ((tiles_h * width) - ncols) / (tiles_h - 1)\n",
    "v_overlap = ((tiles_v * height) - nrows) / (tiles_v - 1)\n",
    "\n",
    "print(f\"Generating {tiles_h * tiles_v} tiles per region with: \\n - tile size: {width} x {height} px \\n - region size: {ncols} x {nrows} px \\n - vertical overlap: {v_overlap} px \\n - horizontal overlap: {h_overlap} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68b600-7947-44d3-88df-cc87334780ff",
   "metadata": {},
   "source": [
    "## Generate Collection\n",
    "\n",
    "Each entry contains the OG file, number of tile and tile image as RGB-array\n",
    "\n",
    "NOTE: In case there are more than one Shapefiles at any point, add mapping here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9321d1d6-81d1-4731-a1dd-19c1d89db5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1133 Point Labels and 602 Shape Labels\n"
     ]
    }
   ],
   "source": [
    "point_labels = []\n",
    "shape_labels = []\n",
    "for file in labels:\n",
    "    with fiona.open(os.path.join(PATH, file)) as shapefile:\n",
    "        for feature in shapefile:\n",
    "            if feature['geometry']['type'] == \"Point\":\n",
    "                point_labels.append(feature[\"geometry\"]['coordinates'][:2])\n",
    "            elif feature['geometry']['type'] == \"Polygon\":\n",
    "                shape = feature[\"geometry\"]['coordinates'][0]\n",
    "                x_min, x_max = min(shape, key = lambda t: t[0])[0], max(shape, key = lambda t: t[0])[0]\n",
    "                y_min, y_max = min(shape, key = lambda t: t[1])[1], max(shape, key = lambda t: t[1])[1]\n",
    "                shape_labels.append([shape, x_min, y_min, x_max, y_max])\n",
    "        \n",
    "point_labels = pd.DataFrame(data=point_labels, columns=[\"X\", \"Y\"])\n",
    "shape_labels = pd.DataFrame(data=shape_labels, columns=[\"Points\", \"Xmin\", \"Ymin\", \"Xmax\", \"Ymax\"])\n",
    "print(f\"Found {len(point_labels)} Point Labels and {len(shape_labels)} Shape Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f230e4a-d5a4-4c7c-bcb6-f572c043e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []\n",
    "for region in regions:\n",
    "    src = rio.open(os.path.join(PATH, region))\n",
    "    name_clean = region.replace(\".tif\",\"\")\n",
    "    \n",
    "    ncols, nrows = src.meta['width'], src.meta['height']\n",
    "    bounds = list(src.bounds)\n",
    "    big_window = rio.windows.Window(col_off = 0, row_off = 0, width = ncols, height = nrows)\n",
    "    \n",
    "    # filter X and Y\n",
    "    region_points = point_labels[(point_labels.X > bounds[0]) & (point_labels.X < bounds[2])]\n",
    "    region_points = region_points[(region_points.Y > bounds[1]) & (region_points.Y < bounds[3])]\n",
    "    # translate to pixels\n",
    "    region_points['X'] = region_points['X'].apply(lambda x: (x - bounds[0])*8) #CHANGE\n",
    "    region_points['Y'] = region_points['Y'].apply(lambda y: (1000 - (y - bounds[1]))*8)\n",
    "    \n",
    "    # traverse tiles column bv column, row by row\n",
    "    for row in range(tiles_v):\n",
    "        row_off = int(row * (height - v_overlap))\n",
    "        for col in range(tiles_v):\n",
    "            col_off = int(col * (width - h_overlap))\n",
    "            # read tile part of region\n",
    "            window = rio.windows.Window(col_off = col_off, row_off = row_off, width = width, height = height).intersection(big_window)\n",
    "            src_image = src.read(window = window)[:3]\n",
    "            image = np.stack((src_image[0], src_image[1], src_image[2]), axis = 2)\n",
    "            # get points in tile \n",
    "            tile_points = region_points[(region_points.X > col_off) & (region_points.X < (col_off+width))]\n",
    "            tile_points = tile_points[(tile_points.Y > row_off) & (tile_points.Y < (row_off+height))]\n",
    "            # translate to new dimensions\n",
    "            tile_points['X'] = tile_points['X'].apply(lambda x: round(x - col_off))\n",
    "            tile_points['Y'] = tile_points['Y'].apply(lambda y: round(y - row_off))\n",
    "            np_points = tile_points.to_numpy()\n",
    "            # add to collection\n",
    "            collection.append({\"file\": name_clean, \"tile\": str(col + (row * tiles_v) + 1), \"image\": image, \"points\": np_points, \"npoints\": len(np_points)})\n",
    "\n",
    "collection = pd.DataFrame(collection)\n",
    "print(f\"Generated Collection of {len(collection)} Tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5e382-520e-460b-9da8-80a6077dff05",
   "metadata": {},
   "source": [
    "## Write To Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f750cc-631c-4e4c-92df-b78728f87073",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_TYPE = \".jpg\"\n",
    "#make new folder in data directory\n",
    "NEW_PATH = os.path.join(PATH, f\"{width}x{height}\")\n",
    "os.mkdir(NEW_PATH)\n",
    "IMAGE_PATH = os.path.join(NEW_PATH, \"images\")\n",
    "os.mkdir(IMAGE_PATH)\n",
    "\n",
    "for index, item in collection.iterrows():\n",
    "    data = item['image']\n",
    "    name = item['file'] + \"_\" + item['tile'] + TARGET_TYPE\n",
    "    #np.save(os.path.join(IMAGE_PATH, name), data) #change TARGET_TYPE\n",
    "    img = Image.fromarray(data, 'RGB')\n",
    "    img.save(os.path.join(IMAGE_PATH, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d2bbf-69da-4be6-acfc-237bf7bb5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PATH = os.path.join(NEW_PATH, \"points\")\n",
    "os.mkdir(LABEL_PATH)\n",
    "items_with_label = collection[collection.npoints > 0]\n",
    "for index, item in items_with_label.iterrows():\n",
    "    data = item['points']\n",
    "    name = item['file'] + \"_\" + item['tile'] + \"_points.npy\"\n",
    "    np.save(os.path.join(LABEL_PATH, name), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedaf8b-a06d-40fb-a3d8-b32b27165ae9",
   "metadata": {},
   "source": [
    "## Define Train, Val and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473d973-4f57-45d8-b083-0c3e3df33640",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETS_PATH = os.path.join(NEW_PATH, \"image_sets\")\n",
    "os.mkdir(SETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb59f6-b44e-4f3c-85a6-8c50ec7d4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT: Full Set\n",
    "finished_set = collection\n",
    "\n",
    "# IDEA 1: only labeled tiles\n",
    "finished_set = collection[collection.npoints > 0]\n",
    "\n",
    "finished_set = finished_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808501f0-aefb-419f-82f8-c4b36be3c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default 70 - 20 - 10 Split\n",
    "total = len(finished_set)\n",
    "train = total * 0.7\n",
    "val = total * 0.2\n",
    "test = total * 0.1\n",
    "TARGET_TYPE = \".jpg\"\n",
    "\n",
    "train_file = open(os.path.join(SETS_PATH, \"training.txt\"), \"w\") \n",
    "val_file = open(os.path.join(SETS_PATH, \"validation.txt\"), \"w\") \n",
    "test_file = open(os.path.join(SETS_PATH, \"test.txt\"), \"w\") \n",
    "\n",
    "for index, item in finished_set.iterrows():\n",
    "    name = item['file'] + \"_\" + item['tile'] + TARGET_TYPE + \"\\n\"\n",
    "    if index < train:\n",
    "        train_file.write(name) \n",
    "    elif index < (train+val):\n",
    "        val_file.write(name) \n",
    "    else:\n",
    "        test_file.write(name)\n",
    "\n",
    "train_file.close() \n",
    "val_file.close()     \n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468e4fe-c9d0-4fa9-8703-07f01d398f5c",
   "metadata": {},
   "source": [
    "# Convolutional Oriented Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89224df-c66b-4e42-b650-8a3d9eabcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread\n",
    "from imgaug import augmenters as iaa\n",
    "from models.base.cobnet import CobNet\n",
    "from imgaug.augmenters import Augmenter\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from helpers.cob.dataset import rescale_augmenter, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1cdee-8c94-4acb-b501-fbd9f55da165",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "PATH = \"/home/jovyan/work/DENMARK/250x250/images\"\n",
    "for _, _, files in os.walk(PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            images.append(file)\n",
    "print(f\"Found {len(images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad60d24-1937-45b3-b851-8045be88b832",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a459c-e4ba-47eb-a864-83d629ff6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_mean=[0.485, 0.456, 0.406]\n",
    "normalization_std=[0.229, 0.224, 0.225]\n",
    "\n",
    "aug = iaa.Sequential([\n",
    "    iaa.size.Resize(250),\n",
    "    rescale_augmenter,\n",
    "    Normalize(mean=normalization_mean, std=normalization_std)\n",
    "])\n",
    "\n",
    "aug_det = aug.to_deterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cef416-b3c5-4ce7-9b26-45d7d4bd5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(images)\n",
    "img_collection = []\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    image = imread(os.path.join(PATH, images[i]))\n",
    "    image = aug_det(images = image[np.newaxis, ...])[0]\n",
    "    image = np.stack((image[:,:,0], image[:,:,1], image[:,:,2]), axis = 0)\n",
    "    #image = image[np.newaxis, ...]\n",
    "\n",
    "    img_collection.append(image)\n",
    "\n",
    "#batch = np.stack(img_collection, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b2ffa-1c4b-4380-b0bb-a9a10c571ebd",
   "metadata": {},
   "source": [
    "## COB Model Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073fcd6-480f-4a60-85ce-97c4bbbb5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "cob_collection = []\n",
    "model = CobNet()\n",
    "model.load_state_dict(torch.load(\"/home/jovyan/work/runs/cob/checkpoints/cp_or.pth.tar\"))\n",
    "\n",
    "for img in tqdm(img_collection):\n",
    "    img_tensor = torch.tensor(img[np.newaxis, ...]).float()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        res = model(img_tensor)\n",
    "    \n",
    "    cob_collection.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2116599-743f-42b5-940d-0a672a1a294b",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a19570-9d93-4eee-b420-7d5453979b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_PATH = \"/home/jovyan/work/DENMARK/250x250/cob\"\n",
    "os.mkdir(NEW_PATH)\n",
    "n = len(cob_collection)\n",
    "\n",
    "for i in range(n):\n",
    "    data = cob_collection[i]['y_fine'].sigmoid()\n",
    "    path = os.path.join(NEW_PATH, images[i])\n",
    "    #np.save(os.path.join(IMAGE_PATH, name), data) #change TARGET_TYPE\n",
    "    save_image(data, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7736f7-3955-468e-83f5-f99306e67e72",
   "metadata": {},
   "source": [
    "# EXPLORATION ZONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fd185-a2bf-4fa3-b1d7-e10be27d5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many 250x250 tiles actually have a label?\n",
    "have = len(collection[collection.npoints > 0])\n",
    "total = len(collection)\n",
    "print(f\"From a total of {total} tiles, {have} have a label assigned ({have/total*100} %)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
