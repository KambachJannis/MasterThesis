{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae71f0c-dcf4-4344-bc1f-e33a679cde29",
   "metadata": {},
   "source": [
    "# MODEL TESTING\n",
    "\n",
    "The purpose of this notebook is to test different model learning configurations. Runs are saved in the standard _runs_ directory and can be referenced by their unique ID (directory name). Each run-directory contains the following files from training:\n",
    "- manager.pkl: run manager object containing all settings of the model run - see implementation _/helpers/run_manager.py_ for details\n",
    "- checkpoint_last.pth: dict containing the most recent state dict for both the model and optimizer (keys: epoch, model, optimizer)\n",
    "- checkpoint_best.pth: same dict as above, but the best performing model over the entire run based on loss\n",
    "- ... and randomly named files from the tensorboard summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6b4323-6e11-4066-9d1b-438f2d4c7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import models\n",
    "import datasets\n",
    "from helpers import io, run_manager, tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd0f3cf-96d2-4e4f-9ef2-a5f723b4f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_ID = \"trees_points_full_final\"\n",
    "\n",
    "DATA_PATH = \"/home/jovyan/work/processed/256x256\"\n",
    "SAVE_PATH = \"/home/jovyan/work/runs\"\n",
    "\n",
    "EM = io.loadPKL(os.path.join(SAVE_PATH, EXP_ID, \"manager.pkl\"))\n",
    "TB = SummaryWriter(EM.save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8b76d-ecc9-4165-abf8-aa4fa40880f9",
   "metadata": {},
   "source": [
    "## Load Model from Run Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d55c014-9fe7-4215-aab2-fdebf1516104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded...\n"
     ]
    }
   ],
   "source": [
    "model = models.getNet(EM.net_name, EM.n_classes).cuda()\n",
    "\n",
    "checkpoint = torch.load(os.path.join(EM.save_path, 'checkpoint_best.pth'))\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "print(\"Model loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d58b2-3ad1-4b26-bc5b-f0ab1ee5cef4",
   "metadata": {},
   "source": [
    "## Load Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "924f937a-0d8a-41d2-a2b4-539b1bf9c346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: \n",
      " - test: 1108\n"
     ]
    }
   ],
   "source": [
    "# load image-lists from files\n",
    "images_path = os.path.join(DATA_PATH, 'image_sets_'+EM.object_type, 'shapes.txt')\n",
    "images_list = [name.replace(\"\\n\",\"\") for name in io.readText(images_path)]\n",
    "test_size = round(len(images_list) * 0.5)\n",
    "test_images = images_list[test_size:]\n",
    "\n",
    "print(f\"Dataset sizes: \\n - test: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ce4950a-23bc-4878-89b6-cbbab0eaa7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders ready...\n"
     ]
    }
   ],
   "source": [
    "test_set = datasets.getDataset(name = 'denmark_shapes',\n",
    "                               path = DATA_PATH,\n",
    "                               images = test_images,\n",
    "                               object_type = EM.object_type,\n",
    "                               n_classes = EM.n_classes,\n",
    "                               transform = EM.transform)\n",
    "\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "test_loader = DataLoader(test_set, sampler = test_sampler,\n",
    "                         batch_size = 16,\n",
    "                         num_workers = 2)\n",
    "\n",
    "print(\"Dataloaders ready...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d4dcc-4a94-44f7-9d9e-a652ed3715e7",
   "metadata": {},
   "source": [
    "## Run Tests\n",
    "\n",
    "Currently supported metrics are:\n",
    "- mean Intersection-over-Union (_mIoU_)\n",
    "- Dice-Score (_dice_)\n",
    "- Pixel Accuracy (_pAccuracy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e293a539-acf5-424e-a5d2-e0f39d1c5cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4fc05dfdf044e897da245e6fc1bac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1883679ae30d4540b37d124a23c173d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31cf79bcdc84b2a8b84bb71076d190b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c69bce8bbe4ec492b1a48b2c5fe588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mIoU      dice  pAccuracy\n",
      "0  0.103486  0.182219   0.958697\n"
     ]
    }
   ],
   "source": [
    "metric_list = [\"mIoU\", \"dice\", \"pAccuracy\"] #mIoU, dice, pAccuracy\n",
    "\n",
    "results_dict = tester.testModel(model, test_loader, metric_list)\n",
    "tester.imagesToTB(model, test_loader, TB, 1)\n",
    "\n",
    "EM.addTest(results_dict)\n",
    "io.savePKL(os.path.join(EM.save_path, 'manager.pkl'), EM)\n",
    "\n",
    "TB.close()\n",
    "print(pd.DataFrame(results_dict, index=[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5584f6-650a-452e-b0ed-99953ab936b0",
   "metadata": {},
   "source": [
    "# EXPLORATION REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a6f1a-b43b-4c59-8953-b1a65cd062d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
