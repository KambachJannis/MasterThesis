{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae71f0c-dcf4-4344-bc1f-e33a679cde29",
   "metadata": {},
   "source": [
    "# MODEL TESTING\n",
    "\n",
    "The purpose of this notebook is to test different model learning configurations. Runs are saved in the standard _runs_ directory and can be referenced by their unique ID (directory name). Each run-directory contains the following files from training:\n",
    "- manager.pkl: run manager object containing all settings of the model run - see implementation _/helpers/run_manager.py_ for details\n",
    "- checkpoint_last.pth: dict containing the most recent state dict for both the model and optimizer (keys: epoch, model, optimizer)\n",
    "- checkpoint_best.pth: same dict as above, but the best performing model over the entire run based on loss\n",
    "- ... and randomly named files from the tensorboard summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6b4323-6e11-4066-9d1b-438f2d4c7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import models\n",
    "import datasets\n",
    "from helpers import io, run_manager, tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd0f3cf-96d2-4e4f-9ef2-a5f723b4f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_ID = \"basic\"\n",
    "\n",
    "DATA_PATH = \"/home/jovyan/work/DENMARK/256x256\"\n",
    "SAVE_PATH = \"/home/jovyan/work/runs\"\n",
    "\n",
    "EM = io.loadPKL(os.path.join(SAVE_PATH, EXP_ID, \"manager.pkl\"))\n",
    "TB = SummaryWriter(EM.save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8b76d-ecc9-4165-abf8-aa4fa40880f9",
   "metadata": {},
   "source": [
    "## Load Model from Run Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55c014-9fe7-4215-aab2-fdebf1516104",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.getNet(EM.net_name, EM.n_classes).cuda()\n",
    "\n",
    "checkpoint = torch.load(os.path.join(EM.save_path, 'checkpoint_best.pth'))\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "print(\"Model loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d58b2-3ad1-4b26-bc5b-f0ab1ee5cef4",
   "metadata": {},
   "source": [
    "## Load Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924f937a-0d8a-41d2-a2b4-539b1bf9c346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: \n",
      " - test: 378\n"
     ]
    }
   ],
   "source": [
    "# load image-lists from files\n",
    "images_path = os.path.join(DATA_PATH, 'image_sets', 'shapes.txt')\n",
    "images_list = [name.replace(\"\\n\",\"\") for name in io.readText(images_path)]\n",
    "test_size = len(images_list) #round(len(images_list) * 0.7)\n",
    "test_images = images_list[:test_size]\n",
    "\n",
    "print(f\"Dataset sizes: \\n - test: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce4950a-23bc-4878-89b6-cbbab0eaa7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders ready...\n"
     ]
    }
   ],
   "source": [
    "test_set = datasets.getDataset(name = 'denmark_shapes',\n",
    "                               path = DATA_PATH,\n",
    "                               images = test_images,\n",
    "                               n_classes = EM.n_classes,\n",
    "                               transform = EM.transform)\n",
    "\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "test_loader = DataLoader(test_set, sampler = test_sampler,\n",
    "                         batch_size = 3,\n",
    "                         num_workers = 2)\n",
    "\n",
    "print(\"Dataloaders ready...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d4dcc-4a94-44f7-9d9e-a652ed3715e7",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bb422-b566-4fa8-9550-1979ae252e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [\"mIoU\", \"dice\", \"pAccuracy\"] #mIoU, dice, pAccuracy\n",
    "\n",
    "results_dict = tester.testModel(model, test_loader, metric_list)\n",
    "tester.imagesToTB(model, test_loader, TB, 30)\n",
    "EM.addTest(results_dict)\n",
    "io.savePKL(os.path.join(EM.save_path, 'manager.pkl'), EM)\n",
    "\n",
    "print(pd.DataFrame(results_dict, index=[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5584f6-650a-452e-b0ed-99953ab936b0",
   "metadata": {},
   "source": [
    "# EXPLORATION REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1bd924-9521-4950-9a91-b9c86200976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EM.test_dicts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28cf853-e637-4d9b-9992-7d3c4c8325d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "batch = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74ad57b3-cc9e-452b-8bb4-6e24ae981369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/DENMARK/256x256/images/2019_1km_6078_637_2.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['meta']['path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd94b4-7938-4d42-92dc-105834b8f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import haven_viz\n",
    "img_src = haven_viz.get_image(images.cpu(), denorm=\"rgb\")\n",
    "y_list, x_list = np.where(points_numpy.squeeze())\n",
    "\n",
    "imagesl = []\n",
    "for blob in point_blobs:\n",
    "    if blob == 0:\n",
    "        continue\n",
    "    blob_mask = blobs==blob\n",
    "    pred_img = haven_viz.mask_on_image(img_src, blob_mask.squeeze()))\n",
    "    \n",
    "\n",
    "img_labels = haven_viz.points_on_image(y_list, x_list, img_src)\n",
    "img_pred = haven_viz.mask_on_image(img_src, blobs.squeeze())\n",
    "img_pred_shape = haven_viz.mask_on_image(img_src, np.array(img).squeeze())\n",
    "\n",
    "stitched_image = np.hstack([img_labels, img_pred, img_pred_shape])\n",
    "stitched_image2 = np.hstack(imagesl)\n",
    "haven_viz.save_image('test.jpg', stitched_image)\n",
    "haven_viz.save_image('test2.jpg', stitched_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374f616-3cce-4677-93d2-560a5f4a59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO WRITE IMAGE TO TENSORBOARD\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images = dataiter.next()['images']\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# write to tensorboard\n",
    "TB.add_image('test', img_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
