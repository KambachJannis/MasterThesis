{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322d4e2c-4ff5-4ec2-84b6-9b37aedcdc8d",
   "metadata": {},
   "source": [
    "# OBJECTNESS EVALUATION\n",
    "\n",
    "The purpose of this Notebook is to evaluate the performance of different generic object proposal approaches on high-resultion satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073b12c7-c2b0-4a85-9ab5-8827e66b74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datasets\n",
    "import helpers.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ba53d2-0b4d-454a-83f5-877230351606",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/jovyan/work/DENMARK/256x256\"\n",
    "SAVE_PATH = \"/home/jovyan/work/runs/OBJECTNESS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96db815-55a5-4adf-9d2b-df175ab37fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.join(DATA_PATH, 'image_sets', 'training.txt')\n",
    "images = [name.replace(\".jpg\\n\",\"\").replace(\".jpg\",\"\") for name in utils.readText(images_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c20844-fffe-4ba6-a924-9e058f93001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.492, 0.475, 0.430]\n",
    "std = [0.176, 0.173, 0.176]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), #convert image to Tensor\n",
    "    transforms.Normalize(mean = mean_new, std = std_new) #normalize Image Tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67f0912-c750-448c-9117-6b53d3159531",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.getDataset(name = \"denmark\", \n",
    "                              path = DATA_PATH,\n",
    "                              images = images,\n",
    "                              n_classes = 1, \n",
    "                              transform = transform)\n",
    "\n",
    "sampler = torch.utils.data.RandomSampler(dataset)\n",
    "loader = DataLoader(dataset, sampler = sampler, batch_size = 1, drop_last = True, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ce5bc9-ea8a-495a-be00-2b838bf81247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00104772 0.00256298 0.00176957] \n",
      " [1.0010378 1.0015213 1.0006772]\n"
     ]
    }
   ],
   "source": [
    "# easy way to determine means and stds for entire dataset - get batch with all images\n",
    "loader = DataLoader(dataset, sampler = sampler, batch_size = len(dataset), drop_last = True, num_workers = 1)\n",
    "dataiter = iter(loader)\n",
    "batch = dataiter.next()\n",
    "print(np.mean(batch['images'].numpy(), axis = (0, 2, 3)), \"\\n\", np.std(batch['images'].numpy(), axis = (0, 2, 3)))\n",
    "# sanity check without axis\n",
    "print(np.mean(batch['images'].numpy()), \"\\n\", np.std(batch['images'].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed4577-2810-4387-965d-9c7cefebd717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
