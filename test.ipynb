{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8de5e-2b87-4fda-9576-bc49981d46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python train.py --root-imgs /home/jovyan/work/cob-test/pascal-voc/VOC2012 --root-segs /home/jovyan/work/cob-test/trainval --run-path /home/jovyan/work/cob-test/runs/cob --cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea8475-5d77-4aa7-a81a-69fa47aad01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "lbl_path = \"trainval/2008_000002.mat\"\n",
    "data = io.loadmat(lbl_path)\n",
    "lbl = data['LabelMap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac98c8a-61ce-4515-aa48-08c7a07778d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599b8a2-b8c0-417d-962a-bd954c87a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.dataloader import interpolate_to_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3749a9-9a9b-445d-922b-82089d0a37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = interpolate_to_polygon(lbl).astype('float64')\n",
    "image *= 255.0/image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee65de-ebe5-46d2-bc08-3aa289481f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.fromarray(np.uint8(image * 255) , 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c079df6-6754-4e22-a99f-6a611870b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c77be-939c-409c-bc49-de600409f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_to_polygon(lbl).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afb12c-0d8c-4f2a-bc52-52037a05c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.dataloader import CobDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea021c2-be70-4b38-a688-759760ebd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_val = CobDataLoader(root_imgs=\"/home/jovyan/work/cob-test/pascal-voc/VOC2012\", root_segs=\"/home/jovyan/work/cob-test/trainval\", split='val')\n",
    "dl_val = DataLoader(dset_val, collate_fn=dset_val.collate_fn, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919222c-3028-41e0-9a91-cdb42f08eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cobnet import CobNet\n",
    "model = CobNet()\n",
    "model.load_state_dict(torch.load(\"runs/cob/checkpoints/cp_or.pth.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd2c4d-4522-48ab-b982-5a2111c1214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl_val))\n",
    "batch = batch[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29334d80-1f6e-4a94-82ce-446b5b2563f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from imgaug import augmenters as iaa\n",
    "from utils.augmenters import Normalize, rescale_augmenter\n",
    "\n",
    "normalization_mean=[0.485, 0.456, 0.406]\n",
    "normalization_std=[0.229, 0.224, 0.225]\n",
    "\n",
    "aug = iaa.Sequential([\n",
    "    iaa.size.Resize(250),\n",
    "    iaa.Flipud(p=0.5),\n",
    "    iaa.Fliplr(p=.5),\n",
    "    iaa.Fliplr(p=.5),\n",
    "    iaa.Rotate([360 / 4 * i for i in range(4)]),\n",
    "    rescale_augmenter,\n",
    "    Normalize(mean=normalization_mean, std=normalization_std)\n",
    "])\n",
    "aug_det = aug.to_deterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b468e5a-58a0-4311-8314-76362264c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(\"pascal-voc/VOC2012/JPEGImages/2007_000033.jpg\")\n",
    "image = image[np.newaxis, ...]\n",
    "#image_t = np.stack((image[:,:,0], image[:,:,1], image[:,:,2]), axis = 0)\n",
    "image2 = imread(\"denmark/1.jpg\")\n",
    "image2 = image2[np.newaxis, ...]\n",
    "#image2_t = np.stack((image2[:,:,0], image2[:,:,1], image2[:,:,2]), axis = 0)\n",
    "\n",
    "sample = aug_det(images=image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43194124-5c13-4ea4-99c7-0f2a04d65689",
   "metadata": {},
   "outputs": [],
   "source": [
    "csample = sample[0]\n",
    "in_img = np.stack((csample[:,:,0], csample[:,:,1], csample[:,:,2]), axis = 0)\n",
    "in_img = in_img[np.newaxis, ...]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    res = model(torch.tensor(in_img).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30092f4-8bdc-4406-8d49-6425457e1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid, save_image\n",
    "n_orient=4\n",
    "\n",
    "fine = res['y_fine'].sigmoid()\n",
    "coarse = res['y_coarse'].sigmoid()\n",
    "\n",
    "total_orients = len(res['orientations'])\n",
    "orients_idx = np.arange(0, total_orients, step=total_orients // n_orient)\n",
    "orients = []\n",
    "for i in orients_idx:\n",
    "    o_ = make_grid(res['orientations'][i].sigmoid(), nrow=1)\n",
    "    orients.append(o_)\n",
    "\n",
    "save_image(fine, 'test.png')\n",
    "save_image(coarse, 'coarse.png')\n",
    "save_image([*orients], 'orients.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9beed-de41-47c7-bbc1-1908c72d0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(image2[0] , 'RGB')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd4c5e-0df8-4136-b8b8-53706e392df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93166a-fcab-4425-9501-e4909fad503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers.cob.cobtrain as cobtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e1d67-0084-4d2f-8f4d-ea94f3122c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'images': \"/home/jovyan/work/ma/helpers/cob/pascal-voc/VOC2012\",\n",
    "    'segments': \"/home/jovyan/work/ma/helpers/cob/trainval\",\n",
    "    'run': \"/home/jovyan/work/runs/cob\",\n",
    "    'lr': 1e-4,\n",
    "    'decay': 2e-4,\n",
    "    'momentum': 0.9,\n",
    "    'epochs-div-lr': 6,\n",
    "    'epochs': 10,\n",
    "    'aug-n-angles': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014664a4-4e0c-4408-8344-741123f9357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cobtrain.initRetrain(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cce1cd-96ee-4bd7-9d28-db1ba068ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "points1 = torch.load(\"/home/jovyan/work/ma/points1.pt\")\n",
    "probs1 = torch.load(\"/home/jovyan/work/ma/probs1.pt\")\n",
    "points16 = torch.load(\"/home/jovyan/work/ma/points16.pt\")\n",
    "probs16 = torch.load(\"/home/jovyan/work/ma/probs16.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd916ee8-3625-4bcf-87ea-2bd96701361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000000])\n",
      "57\n",
      "tensor(63.7695, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from models.losses import lcfcn_loss\n",
    "#loss2 = 0.\n",
    "#for i in range(len(probs16)):\n",
    "loss = lcfcn_loss.computeLoss(points = points16, probs = probs16)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18103347-c631-4b95-b8a6-e938f286f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def getBack(var_grad_fn):\n",
    "    print(var_grad_fn)\n",
    "    for n in var_grad_fn.next_functions:\n",
    "        if n[0]:\n",
    "            try:\n",
    "                tensor = getattr(n[0], 'variable')\n",
    "                print(n[0])\n",
    "                print('Tensor with grad found:', tensor)\n",
    "                print(' - gradient:', tensor.grad)\n",
    "                print()\n",
    "            except AttributeError as e:\n",
    "                getBack(n[0])\n",
    "\n",
    "\n",
    "getBack(loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa283f-bfe7-4470-85f3-ea8597167295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.losses import lcfcn_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e0cdc-3398-41bb-b61d-e1364321374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "points16 = torch.load(\"/home/jovyan/work/ma/points16.pt\")\n",
    "probs16 = torch.load(\"/home/jovyan/work/ma/probs16.pt\")\n",
    "\n",
    "checklist = [2.0794, 9.0109, 3.4657, 2.0794, 7.6246, 4.8520, 2.0794, 2.0794, 4.8520, 7.6246, 3.4657, 2.0794, 3.4657, 2.0794, 4.8520, 2.0794]\n",
    "failed = False\n",
    "\n",
    "for i in range(len(probs16)):\n",
    "    loss = round(lcfcn_loss.computeLoss(points = points16[i].unsqueeze(0), probs = probs16[i].unsqueeze(0)).item(), 4)\n",
    "    if loss != checklist[i]:\n",
    "        failed = True\n",
    "        print(f\"Failed i: {i} with loss: {loss} - should be {checklist[i]}\")\n",
    "\n",
    "if failed == False: print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779284b2-f86e-485f-ae58-c3c7ebf632a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.where(probs1.squeeze().view(-1) == 0.5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502bc087-29f9-4bc3-9447-2c382db4ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50d8c4-533f-4980-932a-a4e6cb9a749f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86753e63-f49e-4567-bacc-31c119a68d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
