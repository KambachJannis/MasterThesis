{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a65fbe-d6c0-45d8-aa4b-6dc201b1760a",
   "metadata": {},
   "source": [
    "# MODEL TRAINING\n",
    "\n",
    "The purpose of this notebook is to train different model learning configurations. Outputs (model checkpoints, configuration dictionary) are saved in the specified directory below. Data path should lead to output folder created during preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "computational-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.backends import cudnn \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "cudnn.benchmark = True # might speed up runtime\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import models\n",
    "import losses\n",
    "import datasets\n",
    "from helpers import io, trainer, run_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b63704-ad47-438a-a5c1-dc28e8488873",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_ID = \"trees_points_full_final\"\n",
    "\n",
    "DATA_PATH = \"/home/jovyan/work/processed/256x256\"\n",
    "SAVE_PATH = \"/home/jovyan/work/runs\"\n",
    "\n",
    "EM = run_manager.Manager(EXP_ID, SAVE_PATH)\n",
    "TB = SummaryWriter(EM.save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-billion",
   "metadata": {},
   "source": [
    "\n",
    "## Data\n",
    "\n",
    "Dataset class takes list of image names as _images_ parameter. These lists for training and validation sets are created in the next cell from .txt files created during preprocessing in the _image_sets_ folder.\n",
    "\n",
    "Preprocessing writes image names to files based on what label-information is available for each image. The denmark_points dataset only returns points and the denmark_shapes dataset only returns shapes - first one should be used for training, second for testing and training of the U-Net. All can return both, with labels which information is available. Currently used for validation to calculate mIoU and loss - be careful when using since output is NOT predictable and data is maybe not passed correctly if the passed labels are left unchecked.\n",
    "\n",
    "Rules for image lists, regarding the specific models:\n",
    "\n",
    "Training:\n",
    "- LCFCN: use denmark_points, list must contain only tiles with points\n",
    "- COB-LCFCN: use denmark_cob, list must contain only tiles with points\n",
    "- UNet: use denmark_shapes, list must contain only tiles with shapes\n",
    "- Mixed: use denmark_all, list must only contain tiles with shapes or points\n",
    "- Stacked: use denmark_stacked, no rules for list\n",
    "\n",
    "Validation:\n",
    "- LCFCN, COB-LCFCN, Mixed: use denmark_all, list must only contain tiles with shapes or points\n",
    "- UNet, Stacked: can stay on denmark_all, should be no problem - change to denmark_shapes for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b8a681-b6ac-4754-ad34-706aafebbea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: \n",
      " - train: 18985 \n",
      " - val: 1108\n"
     ]
    }
   ],
   "source": [
    "# basic settings for dataset\n",
    "EM.object_type = \"trees\" # trees, buildings\n",
    "EM.dataset_type = \"denmark_points\" # denmark_points, denmark_points_cob, denmark_shapes, denmark_all, denmark_stacked\n",
    "EM.n_classes = 2 # 0: background, 1: object = 2\n",
    "EM.batch_size_train = 1\n",
    "EM.batch_size_val = 1\n",
    "\n",
    "# load image-lists from files\n",
    "images_path_points = os.path.join(DATA_PATH, 'image_sets_'+EM.object_type, 'points.txt')\n",
    "images_list_points = [name.replace(\"\\n\",\"\") for name in io.readText(images_path_points)]\n",
    "images_path_shapes = os.path.join(DATA_PATH, 'image_sets_'+EM.object_type, 'shapes.txt')\n",
    "images_list_shapes = [name.replace(\"\\n\",\"\") for name in io.readText(images_path_shapes)]\n",
    "images_list_points_filtered = list(set(images_list_points) - set(images_list_shapes))\n",
    "\n",
    "train_size = 1750 #round(len(images_list_points) * 0.8) #18985 \n",
    "train_images = images_list_points_filtered  #images_list_shapes[:train_size]  \n",
    "val_size =  round(len(images_list_shapes) * 0.5) #round(len(images_list_points) * 0.1)  #1108\n",
    "val_images = images_list_shapes[:val_size]   #images_list_shapes[train_size:(train_size + val_size)]  \n",
    "\n",
    "# create transformation object\n",
    "transform_mean = [0.492, 0.475, 0.430] # from preprocessing\n",
    "transform_std = [0.176, 0.173, 0.176]\n",
    "\n",
    "EM.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize(mean = transform_mean, \n",
    "                                                        std = transform_std)])\n",
    "\n",
    "print(f\"Dataset sizes: \\n - train: {len(train_images)} \\n - val: {len(val_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "controversial-submission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders ready...\n"
     ]
    }
   ],
   "source": [
    "train_set = datasets.getDataset(name = EM.dataset_type,\n",
    "                                path = DATA_PATH,\n",
    "                                images = train_images,\n",
    "                                object_type = EM.object_type,\n",
    "                                n_classes = EM.n_classes,\n",
    "                                transform = EM.transform)\n",
    "\n",
    "train_sampler = torch.utils.data.RandomSampler(train_set)\n",
    "\n",
    "train_loader = DataLoader(train_set, sampler = train_sampler,\n",
    "                          batch_size = EM.batch_size_train, \n",
    "                          drop_last = True, num_workers = 2, pin_memory = True)\n",
    "\n",
    "val_set = datasets.getDataset(name = \"denmark_all\",\n",
    "                              path = DATA_PATH,\n",
    "                              images = val_images,\n",
    "                              object_type = EM.object_type,\n",
    "                              n_classes = EM.n_classes,\n",
    "                              transform = EM.transform)\n",
    "\n",
    "val_sampler = torch.utils.data.SequentialSampler(val_set)\n",
    "\n",
    "val_loader = DataLoader(val_set, sampler = val_sampler,\n",
    "                        batch_size = EM.batch_size_val,\n",
    "                        num_workers = 2, pin_memory = True)\n",
    "\n",
    "print(\"Dataloaders ready...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-uncertainty",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Model can be selected from _vgg16_, _lcfcn_ and _unet_. Available loss functions for point-supervision are _point_ and and _point\\_cob_. \n",
    "\n",
    "Rules for model configuration:\n",
    "- LCFCN: use point type, lcfcn, point loss\n",
    "- COB-LCFCN: use point_cob type, lcfcn, point_cob loss\n",
    "- UNet: use supervised type, unet, dice loss\n",
    "- Mixed: use mixed type, lcfcn, point_cob loss\n",
    "- Stacked: use stacked type, unet, dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amazing-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic settings for model\n",
    "EM.type = 'point' # point, point_cob, supervised, mixed, stacked\n",
    "EM.net_name = 'lcfcn' # lcfcn for point & point_cob, unet for supervised (resnet available)\n",
    "EM.loss_name = 'point' #  point, point_cob, dice (custom) and BCELoss, CrossEntropy (stock)\n",
    "EM.opt_name = 'adam'\n",
    "\n",
    "# optimizer-specific settings\n",
    "EM.adam_learning_rate = 1e-5\n",
    "EM.adam_betas = (0.99, 0.999)\n",
    "EM.adam_decay = 0.0005 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31ada3e-ab93-45e1-8ce3-364f9e635df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready...\n"
     ]
    }
   ],
   "source": [
    "model = models.getNet(EM.net_name, EM.n_classes).cuda()\n",
    "\n",
    "criterion = losses.getLoss(EM.loss_name)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = EM.adam_learning_rate, betas = EM.adam_betas, weight_decay = EM.adam_decay)\n",
    "\n",
    "print(\"Model ready...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-despite",
   "metadata": {},
   "source": [
    "## Run Management\n",
    "\n",
    "Check if a previous run with the same ID exists and either load the last state dicts or move the run folder into the backup folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acknowledged-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new run from epoch 0...\n"
     ]
    }
   ],
   "source": [
    "EM.begin()\n",
    "\n",
    "if os.path.exists(os.path.join(EM.save_path, 'checkpoint_last.pth')):\n",
    "    confirm = input(\"Saved run with same ID found - load (l), rename (r) or cancel (c)?: \")\n",
    "    \n",
    "    if confirm == 'load' or confirm == 'l':\n",
    "        # take epoch settings from manager\n",
    "        EM = io.loadPKL(os.path.join(EM.save_path, 'manager.pkl'))\n",
    "        # load state dicts\n",
    "        checkpoint = torch.load(os.path.join(EM.save_path, 'checkpoint_last.pth'))\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(f\"Loaded previous run - continuing from epoch {EM.current_epoch}...\")\n",
    "   \n",
    "    elif confirm == 'rename' or confirm == 'r':\n",
    "        # rename existing experiment\n",
    "        TB.close()\n",
    "        os.rename(EM.save_path, os.path.join(SAVE_PATH, EM.id+\"_\"+str(np.random.randint(100, 999))))\n",
    "        TB = SummaryWriter(EM.save_path)\n",
    "        print(f\"Starting new run from epoch 0...\")\n",
    "    \n",
    "    else:\n",
    "        print(\"No action taken...\")\n",
    "else:\n",
    "    print(f\"Starting new run from epoch 0...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-marine",
   "metadata": {},
   "source": [
    "## Main Epoch Loop\n",
    "\n",
    "Each epoch conists of training, validation, updating the statstics and saving the best as well as the most recent model and validation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30b970ed880462a92d5e4b27ea93ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac347dbf03084d8880d729e754286469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.4821531830987316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f5749fa26f4db780e006b87acf3a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 4.582385028870257 and mIoU: 0.11801935294753986\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "21     22  2.589658  3.617469  0.097451\n",
      "22     23  2.559167  6.294258  0.116078\n",
      "23     24  2.536203  3.726577  0.109498\n",
      "24     25  2.502527  5.075934  0.130713\n",
      "25     26  2.482153  4.582385  0.118019 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ff21d34d5348d1a56bee3e3a468add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.460009833988841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b444c51e59114b189c9c2d81faf99fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 6.396224819321969 and mIoU: 0.10864152822269639\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "22     23  2.559167  6.294258  0.116078\n",
      "23     24  2.536203  3.726577  0.109498\n",
      "24     25  2.502527  5.075934  0.130713\n",
      "25     26  2.482153  4.582385  0.118019\n",
      "26     27  2.460010  6.396225  0.108642 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe564d421a2419087e67669f5c523d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.4258380915653674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a362acdf37674f3681a28d14ed5a9dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 8.45365916812958 and mIoU: 0.11212033486684167\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "23     24  2.536203  3.726577  0.109498\n",
      "24     25  2.502527  5.075934  0.130713\n",
      "25     26  2.482153  4.582385  0.118019\n",
      "26     27  2.460010  6.396225  0.108642\n",
      "27     28  2.425838  8.453659  0.112120 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6092ee67ea524a2db6e1d48377dc3190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.400635153885441\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74444c6a1ca549c79f7fe78c7357ee31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 4.078821048014693 and mIoU: 0.1106794790588442\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "24     25  2.502527  5.075934  0.130713\n",
      "25     26  2.482153  4.582385  0.118019\n",
      "26     27  2.460010  6.396225  0.108642\n",
      "27     28  2.425838  8.453659  0.112120\n",
      "28     29  2.400635  4.078821  0.110679 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00713e855424fb2952f72c1dda5da8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.378751511238583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8430472efdcb4418a30a2c1e260a3c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 4.3970421464606 and mIoU: 0.09824882698919413\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "25     26  2.482153  4.582385  0.118019\n",
      "26     27  2.460010  6.396225  0.108642\n",
      "27     28  2.425838  8.453659  0.112120\n",
      "28     29  2.400635  4.078821  0.110679\n",
      "29     30  2.378752  4.397042  0.098249 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0275ea75769e4bc097951dfe84318545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.372263618551824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b86984e0c3542c4b893434420a30dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 3.964986970621295 and mIoU: 0.08878723837114802\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "26     27  2.460010  6.396225  0.108642\n",
      "27     28  2.425838  8.453659  0.112120\n",
      "28     29  2.400635  4.078821  0.110679\n",
      "29     30  2.378752  4.397042  0.098249\n",
      "30     31  2.372264  3.964987  0.088787 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bad6449a184b65b521944605b661ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.346562250175382\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5141bf2ad6a3462fba83c07929278a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 5.690737417906781 and mIoU: 0.106368253307116\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "27     28  2.425838  8.453659  0.112120\n",
      "28     29  2.400635  4.078821  0.110679\n",
      "29     30  2.378752  4.397042  0.098249\n",
      "30     31  2.372264  3.964987  0.088787\n",
      "31     32  2.346562  5.690737  0.106368 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9515ecfa2c844e7facf5a2a35c8b53df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.3189613471235524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782c89cbf65a47d8873bf2c83e4215e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 7.646730501280496 and mIoU: 0.11013616599604936\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "28     29  2.400635  4.078821  0.110679\n",
      "29     30  2.378752  4.397042  0.098249\n",
      "30     31  2.372264  3.964987  0.088787\n",
      "31     32  2.346562  5.690737  0.106368\n",
      "32     33  2.318961  7.646731  0.110136 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698b39da6e7a4bf3b95efa88b17eead6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.307119036398298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7b88704cf24fff9c55bdce0ad214f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 4.304953877625896 and mIoU: 0.08128474300256859\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "29     30  2.378752  4.397042  0.098249\n",
      "30     31  2.372264  3.964987  0.088787\n",
      "31     32  2.346562  5.690737  0.106368\n",
      "32     33  2.318961  7.646731  0.110136\n",
      "33     34  2.307119  4.304954  0.081285 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d21d2307bf4aeda3bb98d5b762d295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done with loss: 2.2939544715833575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8150aca64f0f437ea436339a670ebeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation done with loss: 4.502585445705568 and mIoU: 0.10497828251457024\n",
      "\n",
      "     epoch     train  val_loss  val_mIoU\n",
      "30     31  2.372264  3.964987  0.088787\n",
      "31     32  2.346562  5.690737  0.106368\n",
      "32     33  2.318961  7.646731  0.110136\n",
      "33     34  2.307119  4.304954  0.081285\n",
      "34     35  2.293954  4.502585  0.104978 \n",
      "\n",
      "Checkpoint saved... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c9d7277af3451994e53aca57b4cafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EM.epochs = 50\n",
    "start_epoch = EM.current_epoch+1\n",
    "\n",
    "for epoch in tqdm(range(start_epoch, EM.epochs)):\n",
    "    \n",
    "    # Training Phase\n",
    "    train_loss = trainer.trainModel(model, optimizer, train_loader, criterion, EM.type)\n",
    "    TB.add_scalar('training loss', train_loss, epoch)\n",
    "    print(f\"Training done with loss: {train_loss}\")\n",
    "    \n",
    "    # Validation Phase\n",
    "    val_loss_dict = trainer.valModel(model, val_loader, criterion, EM.type)\n",
    "    val_loss = val_loss_dict[\"loss\"]\n",
    "    val_mIoU = val_loss_dict[\"mIoU\"]\n",
    "    TB.add_scalar('validation loss', val_loss, epoch)\n",
    "    TB.add_scalar('validation mIoU', val_mIoU, epoch)\n",
    "    print(f\"Validation done with loss: {val_loss} and mIoU: {val_mIoU}\")\n",
    "    \n",
    "    # update experiment manager with losses\n",
    "    loss_dict = {'epoch': epoch+1, 'train': train_loss, 'val_loss': val_loss, 'val_mIoU': val_mIoU}\n",
    "    EM.loss_list += [loss_dict]\n",
    "    EM.current_epoch = epoch\n",
    "    print(\"\\n\", pd.DataFrame(EM.loss_list).tail(), \"\\n\")\n",
    "    \n",
    "    # save model optimizer and manager as checkpoint\n",
    "    checkpoint = {'epoch': epoch+1, 'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "    torch.save(checkpoint, os.path.join(EM.save_path, 'checkpoint_last.pth'))\n",
    "    io.savePKL(os.path.join(EM.save_path, 'manager.pkl'), EM)\n",
    "    \n",
    "    # check if new best model\n",
    "    if epoch == 0 or val_mIoU > EM.best_loss:\n",
    "        torch.save(checkpoint, os.path.join(EM.save_path, 'checkpoint_best.pth'))\n",
    "        EM.best_loss = val_mIoU\n",
    "        print(\"New best...\")\n",
    "    print(\"Checkpoint saved... \")\n",
    "\n",
    "print(f\"Run completed!\")\n",
    "TB.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f613949-2ddf-46a2-8598-ea8e320cb5e8",
   "metadata": {},
   "source": [
    "# EXPLORATION REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f44c3-2f12-4fe9-8ed5-58b5fb97ca1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
